<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>「环境配置」（二）在云服务器上配置mmtracking环境</title>
      <link href="/2022/05/22/%E3%80%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8D%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9C%A8%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%85%8D%E7%BD%AEmmtracking%E7%8E%AF%E5%A2%83/"/>
      <url>/2022/05/22/%E3%80%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8D%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9C%A8%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%85%8D%E7%BD%AEmmtracking%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<p>参考文章「<a href="https://mmtracking.readthedocs.io/zh_CN/latest/"><strong>mmtrack文档</strong></a>」</p><h3 id="在恒源云下-新建Pytorch1-11-CUDA-1-10-0的环境"><a href="#在恒源云下-新建Pytorch1-11-CUDA-1-10-0的环境" class="headerlink" title="在恒源云下 新建Pytorch1.11 CUDA 1.10.0的环境"></a>在恒源云下 新建Pytorch1.11 CUDA 1.10.0的环境</h3><h3 id="安装VOT数据集测试评估库"><a href="#安装VOT数据集测试评估库" class="headerlink" title="安装VOT数据集测试评估库"></a>安装VOT数据集测试评估库</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/votchallenge/toolkit.git</span><br></pre></td></tr></table></figure><h3 id="安装mmcv-full"><a href="#安装mmcv-full" class="headerlink" title="安装mmcv-full"></a>安装mmcv-full</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mmcv-full==1.5.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html</span><br></pre></td></tr></table></figure><h3 id="安装mmdet"><a href="#安装mmdet" class="headerlink" title="安装mmdet"></a>安装mmdet</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mmdet</span><br></pre></td></tr></table></figure><h3 id="将mmtracking克隆到本地"><a href="#将mmtracking克隆到本地" class="headerlink" title="将mmtracking克隆到本地"></a>将mmtracking克隆到本地</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/open-mmlab/mmtracking.git</span><br><span class="line">cd mmtracking</span><br></pre></td></tr></table></figure><h3 id="安装必备依赖"><a href="#安装必备依赖" class="headerlink" title="安装必备依赖"></a>安装必备依赖</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br><span class="line">pip install setuptools==58.2.0 # 这步非常重要 新版本不再支持easy_install </span><br><span class="line">pip install -v -e .  # or &quot;python setup.py develop&quot;</span><br><span class="line">sudo apt-get install libglib2.0-0</span><br></pre></td></tr></table></figure><span id="more"></span><h3 id="安装额外的依赖"><a href="#安装额外的依赖" class="headerlink" title="安装额外的依赖"></a>安装额外的依赖</h3><h4 id="为-MOTChallenge-评估"><a href="#为-MOTChallenge-评估" class="headerlink" title="为 MOTChallenge 评估"></a>为 MOTChallenge 评估</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/JonathonLuiten/TrackEval.git</span><br></pre></td></tr></table></figure><h4 id="为LVIS评估"><a href="#为LVIS评估" class="headerlink" title="为LVIS评估"></a>为LVIS评估</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/lvis-dataset/lvis-api.git</span><br></pre></td></tr></table></figure><h4 id="为TAO评估"><a href="#为TAO评估" class="headerlink" title="为TAO评估"></a>为TAO评估</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/TAO-Dataset/tao.git</span><br></pre></td></tr></table></figure><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo/demo_mot_vis.py configs/mot/deepsort/sort_faster-rcnn_fpn_4e_mot17-private.py --input demo/demo.mp4 --output mot.mp4</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 环境配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「目标追踪系列」（一）初识目标追踪</title>
      <link href="/2022/05/22/%E3%80%8C%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA%E7%B3%BB%E5%88%97%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89%E5%88%9D%E8%AF%86%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA/"/>
      <url>/2022/05/22/%E3%80%8C%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA%E7%B3%BB%E5%88%97%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89%E5%88%9D%E8%AF%86%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是目标追踪？"><a href="#什么是目标追踪？" class="headerlink" title="什么是目标追踪？"></a>什么是目标追踪？</h2><blockquote><p>转自知乎「<a href="https://zhuanlan.zhihu.com/p/148516834">链接</a>」「<a href="https://kns.cnki.net/KCMS/detail/11.2109.TP.20190104.1506.016.html?uid=WEEvREcwSlJHSldRa1FhdXNXaEd1OFVOaDdwQ0tCckFuaHBIcFFIbUxkbz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!&v=MDU3Nzk0WXc5TXptUm42ajU3VDNmbHFXTTBDTEw3UjdxZWJ1WnNGaUhrVzd6QkpGWT1LQ0xmWWJHNEg5ak1ybzlHWk90">论文原文</a>」</p></blockquote><p>目标追踪是计算机视觉领域的一个重要问题，目前广泛应用在体育赛事转播、安防监控和无人机、无人车、机器人等领域。下面是一些应用的例子。</p><p><img src="https://pic1.zhimg.com/80/v2-531de42fb6687921041aa8a8e6cd2ce8_720w.jpg" alt="田径比赛"></p><p><img src="https://pic3.zhimg.com/80/v2-9b8f472d7c98a1a91b4b93d0d8886b36_720w.jpg" alt="足球比赛"></p><p><img src="https://pic1.zhimg.com/80/v2-deee3ca02a16a4ac0d098acb2390cfac_720w.jpg" alt="车辆追踪"></p><h2 id="目标追踪任务分类"><a href="#目标追踪任务分类" class="headerlink" title="目标追踪任务分类"></a>目标追踪任务分类</h2><h3 id="从目标追踪的用途出发，目标追踪可以分为以下几种任务"><a href="#从目标追踪的用途出发，目标追踪可以分为以下几种任务" class="headerlink" title="从目标追踪的用途出发，目标追踪可以分为以下几种任务"></a>从目标追踪的用途出发，目标追踪可以分为以下几种任务</h3><p><strong>单目标追踪</strong> - 给定一个目标，追踪这个目标的位置。</p><p><strong>多目标追踪</strong> - 追踪多个目标的位置</p><p><strong>Person Re-ID</strong> - 行人重识别，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术。广泛被认为是一个图像检索的子问题。给定一个监控行人图像，检索跨设备下的该行人图像。旨在弥补固定的摄像头的视觉局限，并可与行人检测&#x2F;行人追踪技术相结合。</p><p><strong>MTMCT</strong> - 多目标多摄像头追踪（Multi-target Multi-camera Tracking），追踪多个摄像头拍摄的多个人</p><p><strong>姿态追踪</strong> - 追踪人的姿态</p><h3 id="按照任务计算类型又可以分为以下2类"><a href="#按照任务计算类型又可以分为以下2类" class="headerlink" title="按照任务计算类型又可以分为以下2类"></a>按照任务计算类型又可以分为以下2类</h3><p><strong>在线追踪</strong> - 在线追踪需要实时处理任务，通过过去和现在帧来追踪未来帧中物体的位置。</p><p><strong>离线追踪</strong> - 离线追踪是离线处理任务，可以通过过去、现在和未来的帧来推断物体的位置，因此准确率会在线追踪高。</p><span id="more"></span><h2 id="目标追踪的困难点"><a href="#目标追踪的困难点" class="headerlink" title="目标追踪的困难点"></a>目标追踪的困难点</h2><h3 id="形态变化"><a href="#形态变化" class="headerlink" title="形态变化"></a><strong>形态变化</strong></h3><p> 姿态变化是目标追踪中常见的干扰问题。运动目标发生姿态变化时, 会导致它的特征以及外观模型发生改变, 容易导致追踪失败。例如:体育比赛中的运动员、马路上的行人。</p><h3 id="尺度变化"><a href="#尺度变化" class="headerlink" title="尺度变化"></a><strong>尺度变化</strong></h3><p>尺度的自适应也是目标追踪中的关键问题。当目标尺度缩小时, 由于追踪框不能自适应追踪, 会将很多背景信息包含在内, 导致目标模型的更新错误:当目标尺度增大时, 由于追踪框不能将目标完全包括在内, 追踪框内目标信息不全, 也会导致目标模型的更新错误。因此, 实现尺度自适应追踪是十分必要的。</p><h3 id="遮挡与消失"><a href="#遮挡与消失" class="headerlink" title="遮挡与消失"></a><strong>遮挡与消失</strong></h3><p>目标在运动过程中可能出现被遮挡或者短暂的消失情况。当这种情况发生时, 追踪框容易将遮挡物以及背景信息包含在追踪框内, 会导致后续帧中的追踪目标漂移到遮挡物上面。若目标被完全遮挡时, 由于找不到目标的对应模型, 会导致追踪失败。</p><h3 id="图像模糊"><a href="#图像模糊" class="headerlink" title="图像模糊"></a><strong>图像模糊</strong></h3><p>光照强度变化, 目标快速运动, 低分辨率等情况会导致图像模型, 尤其是在运动目标与背景相似的情况下更为明显。因此, 选择有效的特征对目标和背景进行区分非常必要。</p><h3 id="实例图"><a href="#实例图" class="headerlink" title="实例图"></a>实例图</h3><p><img src="https://pic1.zhimg.com/80/v2-522e7bad45da314edb03ea3c7b26f260_720w.jpg" alt="光照以及模糊"></p><p><img src="https://pic3.zhimg.com/80/v2-46f38d9ee2dd149639774ee598e4456a_720w.jpg" alt="形变以及遮挡"></p><h2 id="目标追踪方法"><a href="#目标追踪方法" class="headerlink" title="目标追踪方法"></a>目标追踪方法</h2><h3 id="按照模式划分可以分为2类"><a href="#按照模式划分可以分为2类" class="headerlink" title="按照模式划分可以分为2类"></a>按照模式划分可以分为2类</h3><h4 id="生成式模型"><a href="#生成式模型" class="headerlink" title="生成式模型"></a><strong>生成式模型</strong></h4><p>早期的工作主要集中于生成式模型追踪算法的研究, 如光流法、粒子滤波、Meanshift算法、Camshift算法等.<strong>此类方法首先建立目标模型或者提取目标特征, 在后续帧中进行相似特征搜索.逐步迭代实现目标定位</strong>.但是这类方法也存在明显的缺点, 就是图像的背景信息没有得到全面的利用.且目标本身的外观变化有随机性和多样性特点, 因此, 通过单一的数学模型描述待追踪目标具有很大的局限性.具体表现为在光照变化, 运动模糊, 分辨率低, 目标旋转形变等情况下, 模型的建立会受到巨大的影响, 从而影响追踪的准确性; 模型的建立没有有效地预测机制, 当出现目标遮挡情况时, 不能够很好地解决。</p><h4 id="鉴别式模型"><a href="#鉴别式模型" class="headerlink" title="鉴别式模型"></a><strong>鉴别式模型</strong></h4><p>鉴别式模型是指, 将目标模型和背景信息同时考虑在内, 通过对比目标模型和背景信息的差异, 将目标模型提取出来, 从而得到当前帧中的目标位置,在对追踪算法的评估中发现, 通过将背景信息引入追踪模型, 可以很好地实现目标追踪.因此鉴别式模型具有很大的优势. 2000年以来, 人们逐渐尝试使用经典的机器学习方法训练分类器, 例如MIL、TLD、支持向量机、结构化学习、随机森林、多实例学习、度量学习. 2010年, 首次将通信领域的相关滤波方法引入到目标追踪中.作为鉴别式方法的一种, 相关滤波无论在速度上还是准确率上, 都显示出更优越的性能.然而, 相关滤波器用于目标追踪是在2014年之后.自2015年以后, 随着深度学习技术的广泛应用, 人们开始将深度学习技术用于目标追踪。</p><h3 id="按照时间顺序"><a href="#按照时间顺序" class="headerlink" title="按照时间顺序"></a>按照时间顺序</h3><p>目标追踪的方法经历了从<strong>经典追踪算法</strong>到<strong>基于核相关滤波算法</strong>，再到<strong>基于深度学习的追踪算法</strong>的过程</p><h4 id="经典追踪算法"><a href="#经典追踪算法" class="headerlink" title="经典追踪算法"></a>经典追踪算法</h4><p>早期的目标追踪算法主要是根据目标建模或者对目标特征进行追踪</p><ol><li>基于目标模型建模的方法 通过对目标外观模型进行建模, 然后在之后的帧中找到目标.例如, 区域匹配、特征点追踪、基于主动轮廓的追踪算法、光流法等.最常用的是特征匹配法, 首先提取目标特征, 然后在后续的帧中找到最相似的特征进行目标定位, 常用的特征有: SIFT特征、SURF特征、Harris角点等。</li><li>基于搜索的方法 随着研究的深入, 人们发现基于目标模型建模的方法对整张图片进行处理, 实时性差.人们将预测算法加入追踪中, 在预测值附近进行目标搜索, 减少了搜索的范围.常见一类的预测算法有Kalman滤波、粒子滤波[8]方法.另一种减小搜索范围的方法是内核方法:运用最速下降法的原理, 向梯度下降方向对目标模板逐步迭代, 直到迭代到最优位置.诸如, Meanshift、Camshift算法</li></ol><h5 id="光流法"><a href="#光流法" class="headerlink" title="光流法"></a><strong>光流法</strong></h5><p>光流法(Lucas-Kanade)的概念首先在1950年提出, 它是针对外观模型对视频序列中的像素进行操作.通过利用视频序列在相邻帧之间的像素关系, 寻找像素的位移变化来判断目标的运动状态, 实现对运动目标的追踪.但是, 光流法适用的范围较小, 需要满足三种假设:图像的光照强度保持不变; 空间一致性, 即每个像素在不同帧中相邻点的位置不变, 这样便于求得最终的运动矢量; 时间连续.光流法适用于目标运动相对于帧率是缓慢的, 也就是两帧之间的目标位移不能太大.</p><h5 id="Meanshift"><a href="#Meanshift" class="headerlink" title="Meanshift"></a><strong>Meanshift</strong></h5><p>Meanshift 方法是一种基于概率密度分布的追踪方法，使目标的搜索一直沿着概率梯度上升的方向，迭代收敛到概率密度分布的局部峰值上。首先 Meanshift 会对目标进行建模，比如利用目标的颜色分布来描述目标，然后计算目标在下一帧图像上的概率分布，从而迭代得到局部最密集的区域。Meanshift 适用于目标的色彩模型和背景差异比较大的情形，早期也用于人脸追踪。由于 Meanshift 方法的快速计算，它的很多改进方法也一直适用至今。</p><h5 id="粒子滤波"><a href="#粒子滤波" class="headerlink" title="粒子滤波"></a><strong>粒子滤波</strong></h5><p>粒子滤波（Particle Filter）方法是一种基于粒子分布统计的方法。以追踪为例，首先对追踪目标进行建模，并定义一种相似度度量确定粒子与目标的匹配程度。在目标搜索的过程中，它会按照一定的分布（比如均匀分布或高斯分布）撒一些粒子，统计这些粒子的相似度，确定目标可能的位置。在这些位置上，下一帧加入更多新的粒子，确保在更大概率上追踪上目标。Kalman Filter 常被用于描述目标的运动模型，它不对目标的特征建模，而是对目标的运动模型进行了建模，常用于估计目标在下一帧的位置。</p><p>可以看到，传统的目标追踪算法存在两个致命的缺陷:</p><ol><li>没有将背景信息考虑在内, 导致在目标遮挡, 光照变化以及运动模糊等干扰下容易出现追踪失败.</li><li>追踪算法执行速度慢(每秒10帧左右), 无法满足实时性的要求.</li></ol><h4 id="基于核相关滤波的追踪算法"><a href="#基于核相关滤波的追踪算法" class="headerlink" title="基于核相关滤波的追踪算法"></a>基于核相关滤波的追踪算法</h4><p>接着，<strong>人们将通信领域的相关滤波(衡量两个信号的相似程度)引入到了目标追踪中</strong>.一些基于相关滤波的追踪算法(MOSSE、CSK、KCF、BACF、SAMF)等, 也随之产生, 速度可以达到数百帧每秒, 可以广泛地应用于实时追踪系统中.其中不乏一些追踪性能优良的追踪器, 诸如SAMF、BACF在OTB数据集和VOT2015竞赛中取得优异成绩。</p><h5 id="MOSSE"><a href="#MOSSE" class="headerlink" title="MOSSE"></a><strong>MOSSE</strong></h5><p>本文提出的相关滤波器（Correlation Filter）通过MOSSE（Minimum Output Sum of Squared Error (MOSSE) filter）算法实现，基本思想：越是相似的两个目标相关值越大，也就是视频帧中与初始化目标越相似，得到的相应也就越大。下图所示通过对比UMACE,ASEF，MOSSE等相关滤波算法，使输出目标中心最大化。</p><h4 id="基于深度学习的追踪算法"><a href="#基于深度学习的追踪算法" class="headerlink" title="基于深度学习的追踪算法"></a><strong>基于深度学习的追踪算法</strong></h4><p>随着深度学习方法的广泛应用, 人们开始考虑将其应用到目标追踪中.人们开始使用深度特征并取得了很好的效果.之后, 人们开始考虑用深度学习建立全新的追踪框架, 进行目标追踪.</p><p>在大数据背景下，利用深度学习训练网络模型，得到的卷积特征输出表达能力更强。在目标追踪上，初期的应用方式是把网络学习到的特征，直接应用到相关滤波或 Struck 的追踪框架里面，从而得到更好的追踪结果，比如前面提到的 DeepSRDCF 方法。本质上卷积输出得到的特征表达，更优于 HOG 或 CN 特征，这也是深度学习的优势之一，但同时也带来了计算量的增加。</p><h2 id="目标追踪方法总结"><a href="#目标追踪方法总结" class="headerlink" title="目标追踪方法总结"></a>目标追踪方法总结</h2><p>目标追踪的方法主要分为2大类，一类是相关滤波、一类是深度学习。</p><p><img src="https://pic2.zhimg.com/80/v2-632a3a08c0f30f0abcdb8b06afbe346d_720w.jpg"></p><ol><li>相比于光流法、Kalman、Meanshift等传统算法，相关滤波类算法追踪速度更快，深度学习类方法精度高.</li><li>具有多特征融合以及深度特征的追踪器在追踪精度方面的效果更好.</li><li>使用强大的分类器是实现良好追踪的基础.</li><li>尺度的自适应以及模型的更新机制也影响着追踪的精度.</li></ol><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>主要的数据集数据对比如下</p><p><img src="https://pic2.zhimg.com/80/v2-469a0d48774e9346242a5fa8e5bd1a39_720w.jpg" alt="数据集对比"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 目标追踪系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「花朵分类项目」（五）长尾分布情况处理</title>
      <link href="/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E4%BA%94%EF%BC%89%E9%95%BF%E5%B0%BE%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5%E5%A4%84%E7%90%86/"/>
      <url>/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E4%BA%94%EF%BC%89%E9%95%BF%E5%B0%BE%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="长尾分布-不均衡数据集"><a href="#长尾分布-不均衡数据集" class="headerlink" title="长尾分布-不均衡数据集"></a>长尾分布-不均衡数据集</h2><p>长尾效应：源自统计学概念，其中有头(Head)和尾(Tail)两个统计学名词，突起部分叫“头”；两边相对平缓的部分叫“尾”。二八法则就是典型的长尾效应，20%的品牌占据了80%的市场</p><p>真实世界中的物体类别是符合长尾分布的 ，更广义的说，是数据不均衡</p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f7dgbe7vj20zk0eit9j.jpg" style="zoom: 50%;" /><p>针对数据不均衡问题，常通过采样方法改善其中有：「<strong>过采样</strong>：样本少的多采样几次」「<strong>欠采样</strong>：样本多的少采样几次」</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f7gfivx3j20zk0awjs0.jpg"></p><p>这里采用Cifar-10的长尾数据集版本「CifarLTDataset」<a href="https://www.cs.toronto.edu/~kriz/cifar.html">下载链接</a></p><h2 id="PB-Sampling"><a href="#PB-Sampling" class="headerlink" title="PB Sampling"></a>PB Sampling</h2><p>「<a href="https://arxiv.org/abs/1910.09217">Decoupling Representation and Classifier for Long-Tailed Recognition</a>」</p><p>Progressively-Balanced Sampling （渐进式采样策略）：采样权重随着$Epoch$的增加渐进式的变化</p><span id="more"></span><p>从原始分布逐渐变为分类均衡，有效提升不均衡分类精度<br>$$<br>p_j &#x3D; \frac{n_j^q}{\sum_{i&#x3D;1}^Cn_i^q}<br>$$</p><p>$$<br>p_j^{PB}(t) &#x3D; (1 - \frac{t}{T})p_j^{IB} + \frac{t}{T}p_j^{CB}<br>$$</p><p>$p_j$：第 $j$类采样概率，$n_j$：第 $j$类样本数量，$C$：总类别数，$q$：超参数，用于控制概率$p_j$，值域$[0, 1]$</p><p>$t, T$：第$t$个$Epoch$，$T$表示总共有多少个$Epoch$</p><p>$P_j^{IB}$：当第一个公式的$q$取1时得到的策略；样本多，采样概率高</p><p>$P_j^{CB}$：当第一个公式的$q$取0时得到的策略；$p_j$全都相等，都是$1&#x2F;C$</p><p>$P_j^{IB}$是原始分布「$IB(Instance-Balanced)$」，$P_j^{CB}$是均衡分布「$CB(Class-Balanced)$」</p><p>第二个公式表示「一开始是原始分布，随着$t$增加逐渐均衡」</p><h2 id="Dataset-与-Dataloader"><a href="#Dataset-与-Dataloader" class="headerlink" title="Dataset 与 Dataloader"></a>Dataset 与 Dataloader</h2><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f8jhk5stj20ib0bkjrw.jpg"></p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f8mzha9dj20g5070aac.jpg"></p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f99551p8j20of0h5t9k.jpg" style="zoom:67%;" /><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="datasets-x2F-cifar-longtail-py"><a href="#datasets-x2F-cifar-longtail-py" class="headerlink" title="datasets&#x2F;cifar_longtail.py"></a>datasets&#x2F;cifar_longtail.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :cifar_longtail.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-11</span></span><br><span class="line"><span class="string"># @brief        :cifar-10长尾数据集的读取</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CifarDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    names = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line">    cls_num = <span class="built_in">len</span>(names)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.img_info = []      <span class="comment"># 定义list用于存储样本路径、标签</span></span><br><span class="line">        self._get_img_info()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        path_img, label = self.img_info[index]</span><br><span class="line">        img = Image.<span class="built_in">open</span>(path_img).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, label, path_img</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.img_info) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;\ndata_dir:&#123;&#125; is a empty dir! Please checkout your path to images!&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                self.root_dir))   <span class="comment"># 代码具有友好的提示功能，便于debug</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_info)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_img_info</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> root, dirs, _ <span class="keyword">in</span> os.walk(self.root_dir):</span><br><span class="line">            <span class="comment"># 遍历类别</span></span><br><span class="line">            <span class="keyword">for</span> sub_dir <span class="keyword">in</span> dirs:</span><br><span class="line">                img_names = os.listdir(os.path.join(root, sub_dir))</span><br><span class="line">                img_names = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x.endswith(<span class="string">&#x27;.png&#x27;</span>), img_names))</span><br><span class="line">                <span class="comment"># 遍历图片</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img_names)):</span><br><span class="line">                    img_name = img_names[i]</span><br><span class="line">                    path_img = os.path.abspath(os.path.join(root, sub_dir, img_name))</span><br><span class="line">                    label = <span class="built_in">int</span>(sub_dir)</span><br><span class="line">                    self.img_info.append((path_img, <span class="built_in">int</span>(label)))</span><br><span class="line">        random.shuffle(self.img_info)   <span class="comment"># 将数据顺序打乱</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CifarLTDataset</span>(<span class="title class_ inherited__">CifarDataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, transform=<span class="literal">None</span>, imb_factor=<span class="number">0.01</span>, isTrain=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param root_dir:</span></span><br><span class="line"><span class="string">        :param transform:</span></span><br><span class="line"><span class="string">        :param imb_type:</span></span><br><span class="line"><span class="string">        :param imb_factor: float, 值越小，数量下降越快,0.1表示最少的类是最多的类的0.1倍，如500：5000</span></span><br><span class="line"><span class="string">        :param isTrain:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(CifarLTDataset, self).__init__(root_dir, transform=transform)</span><br><span class="line">        self.imb_factor = imb_factor</span><br><span class="line">        <span class="keyword">if</span> isTrain:</span><br><span class="line">            self.nums_per_cls = self._get_img_num_per_cls()     <span class="comment"># 计算每个类的样本数</span></span><br><span class="line">            self._select_img()      <span class="comment"># 采样获得符合长尾分布的数据量</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 非训练状态，可采用均衡数据集测试</span></span><br><span class="line">            self.nums_per_cls = []</span><br><span class="line">            <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(self.cls_num):</span><br><span class="line">                label_list = [label <span class="keyword">for</span> p, label <span class="keyword">in</span> self.img_info]  <span class="comment"># 获取每个标签</span></span><br><span class="line">                self.nums_per_cls.append(label_list.count(n))       <span class="comment"># 统计每个类别数量</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_select_img</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        根据每个类需要的样本数进行挑选</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        new_lst = []</span><br><span class="line">        <span class="keyword">for</span> n, img_num <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.nums_per_cls):</span><br><span class="line">            lst_tmp = [info <span class="keyword">for</span> info <span class="keyword">in</span> self.img_info <span class="keyword">if</span> info[<span class="number">1</span>] == n]  <span class="comment"># 获取第n类别数据信息</span></span><br><span class="line">            random.shuffle(lst_tmp)</span><br><span class="line">            lst_tmp = lst_tmp[:img_num]</span><br><span class="line">            new_lst.extend(lst_tmp)</span><br><span class="line">        random.shuffle(new_lst)</span><br><span class="line">        self.img_info = new_lst</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_img_num_per_cls</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        依长尾分布计算每个类别应有多少张样本</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        img_max = <span class="built_in">len</span>(self.img_info) / self.cls_num</span><br><span class="line">        img_num_per_cls = []</span><br><span class="line">        <span class="keyword">for</span> cls_idx <span class="keyword">in</span> <span class="built_in">range</span>(self.cls_num):</span><br><span class="line">            num = img_max * (self.imb_factor ** (cls_idx / (self.cls_num - <span class="number">1.0</span>)))  <span class="comment"># 列出公式就知道了</span></span><br><span class="line">            img_num_per_cls.append(<span class="built_in">int</span>(num))</span><br><span class="line">        <span class="keyword">return</span> img_num_per_cls</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    root_dir = <span class="string">r&quot;/Users/kenton/Downloads/deeplearning_dataset/cifar-10/cifar10_train&quot;</span></span><br><span class="line">    train_dataset = CifarLTDataset(root_dir, imb_factor=<span class="number">0.01</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(train_dataset))</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataset)))</span><br><span class="line">    <span class="built_in">print</span>(train_dataset.nums_per_cls)</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    y = train_dataset.nums_per_cls</span><br><span class="line">    x = <span class="built_in">range</span>(<span class="built_in">len</span>(y))</span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    <span class="comment"># plt.show()</span></span><br></pre></td></tr></table></figure><h3 id="bins-x2F-parse-cifar-to-png-py"><a href="#bins-x2F-parse-cifar-to-png-py" class="headerlink" title="bins&#x2F;parse_cifar_to_png.py"></a>bins&#x2F;parse_cifar_to_png.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name  : parse_cifar10_to_png.py</span></span><br><span class="line"><span class="string"># @author     : zz0320</span></span><br><span class="line"><span class="string"># @date       : 2021-04-11</span></span><br><span class="line"><span class="string"># @brief      : 将cifar10数据pickle形式解析成png格式</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> imageio <span class="keyword">import</span> imwrite</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">unpickle</span>(<span class="params">file</span>):</span><br><span class="line">    fo = <span class="built_in">open</span>(file, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> sys.version_info &lt; (<span class="number">3</span>, <span class="number">0</span>):</span><br><span class="line">        dict_ = pickle.load(fo)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dict_ = pickle.load(fo, encoding=<span class="string">&#x27;bytes&#x27;</span>)</span><br><span class="line">    fo.close()</span><br><span class="line">    <span class="keyword">return</span> dict_</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_mkdir</span>(<span class="params">my_dir</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(my_dir):</span><br><span class="line">        os.makedirs(my_dir)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pasre_pickle_img</span>(<span class="params">pkl_data</span>):</span><br><span class="line">    img = np.reshape(pkl_data[<span class="string">b&#x27;data&#x27;</span>][i], (<span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">    label_n = <span class="built_in">str</span>(pkl_data[<span class="string">b&#x27;labels&#x27;</span>][i])</span><br><span class="line">    img = img.transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))  <span class="comment"># c*h*w --&gt; h*w*c</span></span><br><span class="line">    <span class="keyword">return</span> img, label_n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_data_dir</span>(<span class="params">path_data</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path_data):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;文件夹不存在，请检查数据是否存放到data_dir变量:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(path_data))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    BASE_DIR = os.path.dirname(__file__)</span><br><span class="line">    cifar_dir = <span class="string">r&quot;/Users/kenton/Downloads/deeplearning_dataset/cifar-10&quot;</span>    <span class="comment"># 数据目录</span></span><br><span class="line">    data_dir = os.path.join(cifar_dir, <span class="string">&quot;cifar-10-batches-py&quot;</span>)           <span class="comment"># 源数据目录</span></span><br><span class="line">    check_data_dir(data_dir)</span><br><span class="line">    train_o_dir = os.path.join(cifar_dir, <span class="string">&quot;cifar10_train&quot;</span>)              <span class="comment"># 输出的目录</span></span><br><span class="line">    test_o_dir = os.path.join(cifar_dir, <span class="string">&quot;cifar10_test&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># train data</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">        data_path = os.path.join(data_dir,  <span class="string">&quot;data_batch_&quot;</span> + <span class="built_in">str</span>(j))  <span class="comment"># data_batch_12345</span></span><br><span class="line">        train_data = unpickle(data_path)</span><br><span class="line">        <span class="built_in">print</span>(data_path + <span class="string">&quot; is loading...&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10000</span>):</span><br><span class="line">            <span class="comment"># 解析图片及标签</span></span><br><span class="line">            img, label_num = pasre_pickle_img(train_data)</span><br><span class="line">            <span class="comment"># 创建文件夹</span></span><br><span class="line">            o_dir = os.path.join(train_o_dir, label_num)</span><br><span class="line">            my_mkdir(o_dir)</span><br><span class="line">            <span class="comment"># 保存图片</span></span><br><span class="line">            img_name = label_num + <span class="string">&#x27;_&#x27;</span> + <span class="built_in">str</span>(i + (j - <span class="number">1</span>)*<span class="number">10000</span>) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">            img_path = os.path.join(o_dir, img_name)</span><br><span class="line">            imwrite(img_path, img)</span><br><span class="line">        <span class="built_in">print</span>(data_path + <span class="string">&quot; loaded.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test data</span></span><br><span class="line">    test_data_path = os.path.join(data_dir, <span class="string">&quot;test_batch&quot;</span>)</span><br><span class="line">    test_data = unpickle(test_data_path)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10000</span>):</span><br><span class="line">        <span class="comment"># 解析图片及标签</span></span><br><span class="line">        img, label_num = pasre_pickle_img(test_data)</span><br><span class="line">        <span class="comment"># 创建文件夹</span></span><br><span class="line">        o_dir = os.path.join(test_o_dir, label_num)</span><br><span class="line">        my_mkdir(o_dir)</span><br><span class="line">        <span class="comment"># 保存图片</span></span><br><span class="line">        img_name = label_num + <span class="string">&#x27;_&#x27;</span> + <span class="built_in">str</span>(i) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">        img_path = os.path.join(o_dir, img_name)</span><br><span class="line">        imwrite(img_path, img)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;done.&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="models-x2F-resnet-cifar10-py"><a href="#models-x2F-resnet-cifar10-py" class="headerlink" title="models&#x2F;resnet_cifar10.py"></a>models&#x2F;resnet_cifar10.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Properly implemented ResNet-s for CIFAR10 as described in paper [1].</span></span><br><span class="line"><span class="string">The implementation and structure of this file is hugely influenced by [2]</span></span><br><span class="line"><span class="string">which is implemented for ImageNet and doesn&#x27;t have option A for identity.</span></span><br><span class="line"><span class="string">Moreover, most of the implementations on the web is copy-paste from</span></span><br><span class="line"><span class="string">torchvision&#x27;s resnet and has wrong number of params.</span></span><br><span class="line"><span class="string">Proper ResNet-s for CIFAR10 (for fair comparision and etc.) has following</span></span><br><span class="line"><span class="string">number of layers and parameters:</span></span><br><span class="line"><span class="string">name      | layers | params</span></span><br><span class="line"><span class="string">ResNet20  |    20  | 0.27M</span></span><br><span class="line"><span class="string">ResNet32  |    32  | 0.46M</span></span><br><span class="line"><span class="string">ResNet44  |    44  | 0.66M</span></span><br><span class="line"><span class="string">ResNet56  |    56  | 0.85M</span></span><br><span class="line"><span class="string">ResNet110 |   110  |  1.7M</span></span><br><span class="line"><span class="string">ResNet1202|  1202  | 19.4m</span></span><br><span class="line"><span class="string">which this implementation indeed has.</span></span><br><span class="line"><span class="string">Reference:</span></span><br><span class="line"><span class="string">[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</span></span><br><span class="line"><span class="string">    Deep Residual Learning for Image Recognition. arXiv:1512.03385</span></span><br><span class="line"><span class="string">[2] https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py</span></span><br><span class="line"><span class="string">If you use this implementation in you work, please don&#x27;t forget to mention the</span></span><br><span class="line"><span class="string">author, Yerlan Idelbayev.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn.init <span class="keyword">as</span> init</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">__all__ = [<span class="string">&#x27;ResNet&#x27;</span>, <span class="string">&#x27;resnet20&#x27;</span>, <span class="string">&#x27;resnet32&#x27;</span>, <span class="string">&#x27;resnet44&#x27;</span>, <span class="string">&#x27;resnet56&#x27;</span>, <span class="string">&#x27;resnet110&#x27;</span>, <span class="string">&#x27;resnet1202&#x27;</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">__all__ 是针对模块公开接口的一种约定，以提供了”白名单“的形式暴露接口</span></span><br><span class="line"><span class="string">使用from xxx import *导入该文件时，只会导入 __all__ 列出的成员</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_weights_init</span>(<span class="params">m</span>):</span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line">    <span class="comment">#print(classname)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear) <span class="keyword">or</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">        init.kaiming_normal_(m.weight)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LambdaLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, lambd</span>):</span><br><span class="line">        <span class="built_in">super</span>(LambdaLayer, self).__init__()</span><br><span class="line">        self.lambd = lambd</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lambd(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_planes, planes, stride=<span class="number">1</span>, option=<span class="string">&#x27;A&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line"></span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_planes != planes:</span><br><span class="line">            <span class="keyword">if</span> option == <span class="string">&#x27;A&#x27;</span>:</span><br><span class="line">                <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                For CIFAR10 ResNet paper uses option A.</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                self.shortcut = LambdaLayer(<span class="keyword">lambda</span> x:</span><br><span class="line">                                            F.pad(x[:, :, ::<span class="number">2</span>, ::<span class="number">2</span>], (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, planes//<span class="number">4</span>, planes//<span class="number">4</span>), <span class="string">&quot;constant&quot;</span>, <span class="number">0</span>))</span><br><span class="line">            <span class="keyword">elif</span> option == <span class="string">&#x27;B&#x27;</span>:</span><br><span class="line">                self.shortcut = nn.Sequential(</span><br><span class="line">                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                     nn.BatchNorm2d(self.expansion * planes)</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        out = self.bn2(self.conv2(out))</span><br><span class="line">        out += self.shortcut(x)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, num_blocks, num_classes=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.in_planes = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">16</span>, num_blocks[<span class="number">0</span>], stride=<span class="number">1</span>)  <span class="comment"># 原版16</span></span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">32</span>, num_blocks[<span class="number">1</span>], stride=<span class="number">2</span>)  <span class="comment"># 原版32</span></span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">64</span>, num_blocks[<span class="number">2</span>], stride=<span class="number">2</span>)  <span class="comment"># 原版64</span></span><br><span class="line">        self.linear = nn.Linear(<span class="number">64</span>, num_classes)</span><br><span class="line"></span><br><span class="line">        self.apply(_weights_init)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, planes, num_blocks, stride</span>):</span><br><span class="line">        strides = [stride] + [<span class="number">1</span>]*(num_blocks-<span class="number">1</span>)</span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> stride <span class="keyword">in</span> strides:</span><br><span class="line">            layers.append(block(self.in_planes, planes, stride))</span><br><span class="line">            self.in_planes = planes * block.expansion</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        out = self.layer1(out)</span><br><span class="line">        out = self.layer2(out)</span><br><span class="line">        out = self.layer3(out)</span><br><span class="line">        out = F.avg_pool2d(out, out.size()[<span class="number">3</span>])</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = self.linear(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet8</span>(<span class="params">num_classes=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet20</span>(<span class="params">num_classes=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>], num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet32</span>(<span class="params">num_classes=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>], num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet44</span>():</span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet56</span>(<span class="params">num_classes=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>], num_classes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet110</span>():</span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">18</span>, <span class="number">18</span>, <span class="number">18</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet1202</span>():</span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">200</span>, <span class="number">200</span>, <span class="number">200</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    fake_img = torch.randn((<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">    <span class="keyword">for</span> net_name <span class="keyword">in</span> __all__:</span><br><span class="line">        <span class="keyword">if</span> net_name.startswith(<span class="string">&#x27;resnet&#x27;</span>):</span><br><span class="line">            model = <span class="built_in">globals</span>()[net_name]()  <span class="comment"># globals()以字典形式返回全局变量</span></span><br><span class="line">            output = model(fake_img)</span><br><span class="line">            <span class="built_in">print</span>(net_name, output.shape)</span><br></pre></td></tr></table></figure><h3 id="tools-x2F-progressively-balance-py"><a href="#tools-x2F-progressively-balance-py" class="headerlink" title="tools&#x2F;progressively_balance.py"></a>tools&#x2F;progressively_balance.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :progressively_balance.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-12</span></span><br><span class="line"><span class="string"># @brief        :渐进式平衡采样 progressive_balance功能实现</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="comment"># matplotlib.use(&#x27;agg&#x27;)</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">BASE_DIR = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line">sys.path.append(os.path.join(BASE_DIR, <span class="string">&#x27;..&#x27;</span>))</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, WeightedRandomSampler</span><br><span class="line"><span class="keyword">from</span> datasets.cifar_longtail <span class="keyword">import</span> CifarLTDataset</span><br><span class="line"><span class="keyword">from</span> tools.common_tools <span class="keyword">import</span> check_data_dir</span><br><span class="line"><span class="keyword">from</span> config.cifar_config <span class="keyword">import</span> cfg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProgressiveSampler</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataset, max_epoch</span>):</span><br><span class="line">        self.max_epoch = max_epoch</span><br><span class="line">        self.dataset = dataset      <span class="comment"># dataset</span></span><br><span class="line">        self.train_targets = [<span class="built_in">int</span>(info[<span class="number">1</span>]) <span class="keyword">for</span> info <span class="keyword">in</span> dataset.img_info]    <span class="comment">#  hard code，记录各个样本的标签</span></span><br><span class="line">        self.nums_per_cls = dataset.nums_per_cls        <span class="comment"># 记录每个类别的样本数量</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_cal_class_prob</span>(<span class="params">self, q</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        根据q值计算每个类的采样概率，公式中的 p_j</span></span><br><span class="line"><span class="string">        :param q: float , [0, 1]</span></span><br><span class="line"><span class="string">        :return: list,</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        num_pow = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">pow</span>(x, q), self.nums_per_cls))</span><br><span class="line">        sigma_num_pow = <span class="built_in">sum</span>(num_pow)</span><br><span class="line">        cls_prob = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x/sigma_num_pow, num_pow))</span><br><span class="line">        <span class="keyword">return</span> cls_prob</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_cal_pb_prob</span>(<span class="params">self, t</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        progressively-balanced 概率计算</span></span><br><span class="line"><span class="string">        :param t: 当前epoch数</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        p_ib = self._cal_class_prob(q=<span class="number">1</span>)</span><br><span class="line">        p_cb = self._cal_class_prob(q=<span class="number">0</span>)</span><br><span class="line">        p_pb = (<span class="number">1</span> - t/self.max_epoch) * np.array(p_ib) + (t/self.max_epoch) * np.array(p_cb)</span><br><span class="line"></span><br><span class="line">        p_pb /= np.array(self.nums_per_cls)  <span class="comment"># very important！由于pytorch的sampler机制是按每个样本采样，所以要除以样本总数</span></span><br><span class="line">        <span class="keyword">return</span> p_pb.tolist()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, epoch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        生成sampler</span></span><br><span class="line"><span class="string">        :param epoch:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        p_pb = self._cal_pb_prob(t=epoch)</span><br><span class="line">        p_pb = torch.tensor(p_pb, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        samples_weights = p_pb[self.train_targets]  <span class="comment"># 计算每个样本被采样的权重，这里是依据样本的类别来赋权，self.train_targets是标签</span></span><br><span class="line">        <span class="comment"># weights：要求是每个样本赋予weight</span></span><br><span class="line">        <span class="comment"># num_samples：该sampler一个epoch采样数量</span></span><br><span class="line">        sampler = WeightedRandomSampler(weights=samples_weights, num_samples=<span class="built_in">len</span>(samples_weights))</span><br><span class="line">        <span class="comment"># sampler = WeightedRandomSampler(weights=samples_weights, num_samples=1000)</span></span><br><span class="line">        <span class="keyword">return</span> sampler, p_pb</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plot_line</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.max_epoch):</span><br><span class="line">            _, weights = self(i)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">19</span>:</span><br><span class="line">                x = <span class="built_in">range</span>(<span class="built_in">len</span>(weights))</span><br><span class="line">                plt.plot(x, weights, label=<span class="string">&quot;t=&quot;</span>+<span class="built_in">str</span>(i))</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.title(<span class="string">&quot;max epoch=&quot;</span>+<span class="built_in">str</span>(self.max_epoch))</span><br><span class="line">        plt.xlabel(<span class="string">&quot;class index sorted by numbers&quot;</span>)</span><br><span class="line">        plt.ylabel(<span class="string">&quot;weights&quot;</span>)</span><br><span class="line">        <span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 设置路径</span></span><br><span class="line">    train_dir = <span class="string">r&quot;/Users/kenton/Downloads/deeplearning_dataset/cifar-10/cifar10_train&quot;</span></span><br><span class="line">    check_data_dir(train_dir)</span><br><span class="line">    train_data = CifarLTDataset(root_dir=train_dir, transform=cfg.transforms_train, isTrain=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    max_epoch = <span class="number">200</span></span><br><span class="line">    sampler_generator = ProgressiveSampler(train_data, max_epoch)</span><br><span class="line">    sampler_generator.plot_line()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">20</span> != <span class="number">19</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        sampler, _ = sampler_generator(epoch)</span><br><span class="line">        train_loader = DataLoader(dataset=train_data, batch_size=cfg.train_bs, shuffle=<span class="literal">False</span>, num_workers=cfg.workers,</span><br><span class="line">                                  sampler=sampler)</span><br><span class="line">        labels = []</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> train_loader:</span><br><span class="line">            _, label, _ = data</span><br><span class="line">            labels.extend(label.tolist())</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch:&#123;&#125;, Counter:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch, Counter(labels)))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="config-x2F-cifar-config-py"><a href="#config-x2F-cifar-config-py" class="headerlink" title="config&#x2F;cifar_config.py"></a>config&#x2F;cifar_config.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :cifar_config.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-12</span></span><br><span class="line"><span class="string"># @brief        :cifar网络参数配置</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets.flower102 <span class="keyword">import</span> FlowerDataset</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> easydict <span class="keyword">import</span> EasyDict</span><br><span class="line">BASE_DIR = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line">sys.path.append(os.path.join(BASE_DIR, <span class="string">&#x27;..&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cfg = EasyDict() <span class="comment"># 访问属性的方式去使用key-value 即通过key 或者 value</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cfg.model_name = &quot;resnet&quot;</span></span><br><span class="line"><span class="comment"># cfg.model_name = &quot;vgg16_bn&quot;</span></span><br><span class="line"><span class="comment"># cfg.model_name = &quot;se_resnet50&quot;</span></span><br><span class="line"></span><br><span class="line">cfg.pb = <span class="literal">True</span></span><br><span class="line">cfg.mixup = <span class="literal">False</span>  <span class="comment"># 是否采用mixup</span></span><br><span class="line">cfg.mixup_alpha = <span class="number">1.</span>  <span class="comment"># beta分布的参数. beta分布是一组定义在(0,1) 区间的连续概率分布。</span></span><br><span class="line">cfg.label_smooth = <span class="literal">False</span>  <span class="comment"># 是否采用标签平滑</span></span><br><span class="line">cfg.label_smooth_eps = <span class="number">0.01</span>  <span class="comment"># 标签平滑超参数 eps</span></span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&quot;/Users/kenton/Downloads/deeplearning_dataset&quot;</span></span><br><span class="line">cfg.path_resnet18 = os.path.join(data_dir, <span class="string">&quot;pretrained_model&quot;</span>, <span class="string">&quot;resnet18-f37072fd.pth&quot;</span>)</span><br><span class="line">cfg.path_vgg16bn = os.path.join(data_dir, <span class="string">&quot;pretrained_model&quot;</span>, <span class="string">&quot;vgg16_bn-6c64b313.pth&quot;</span>)</span><br><span class="line">cfg.path_se_res50 = os.path.join(data_dir, <span class="string">&quot;pretrained_model&quot;</span>, <span class="string">&quot;seresnet50-60a8950a85b2b.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练参数</span></span><br><span class="line">cfg.train_bs = <span class="number">128</span> <span class="comment"># batchsize</span></span><br><span class="line">cfg.valid_bs = <span class="number">128</span></span><br><span class="line">cfg.workers = <span class="number">4</span> <span class="comment">#线程个数</span></span><br><span class="line"></span><br><span class="line">cfg.lr_init = <span class="number">0.1</span></span><br><span class="line">cfg.momentum = <span class="number">0.9</span></span><br><span class="line">cfg.weight_decay = <span class="number">1e-4</span> <span class="comment"># 权重衰减</span></span><br><span class="line"></span><br><span class="line">cfg.factor = <span class="number">0.1</span>  <span class="comment"># 权重更新的比例</span></span><br><span class="line">cfg.milestones = [<span class="number">160</span>, <span class="number">180</span>]  <span class="comment"># 什么时候下降学习率</span></span><br><span class="line">cfg.max_epoch = <span class="number">200</span></span><br><span class="line"></span><br><span class="line">cfg.log_interval = <span class="number">20</span>  <span class="comment"># 日志打印间隔</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 数据集</span></span><br><span class="line">norm_mean = [<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>]</span><br><span class="line">norm_std = [<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>] <span class="comment"># cifar-10统计得到的</span></span><br><span class="line">normTransform = transforms.Normalize(norm_mean, norm_std)</span><br><span class="line"></span><br><span class="line">cfg.transforms_train = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">32</span>)),</span><br><span class="line">    <span class="comment"># transforms.CenterCrop(256),</span></span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    transforms.RandomCrop(<span class="number">32</span>, padding=<span class="number">4</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    normTransform,</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">cfg.transforms_valid = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    normTransform,</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h3 id="src-x2F-cifar-train-py"><a href="#src-x2F-cifar-train-py" class="headerlink" title="src&#x2F;cifar_train.py"></a>src&#x2F;cifar_train.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :cifar_train.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-12</span></span><br><span class="line"><span class="string"># @brief        :cifar-10训练代码</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">BASE_DIR = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line">sys.path.append(os.path.join(BASE_DIR, <span class="string">&#x27;..&#x27;</span>))</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> tools.model_trainer <span class="keyword">import</span> ModelTrainer</span><br><span class="line"><span class="keyword">from</span> tools.mixup <span class="keyword">import</span> mixup_data, mixup_criterion</span><br><span class="line"><span class="keyword">from</span> tools.common_tools <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> tools.my_loss <span class="keyword">import</span> LabelSmoothLoss</span><br><span class="line"><span class="keyword">from</span> models.resnet_cifar10 <span class="keyword">import</span> resnet20</span><br><span class="line"><span class="keyword">from</span> config.cifar_config <span class="keyword">import</span> cfg</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> datasets.cifar_longtail <span class="keyword">import</span> CifarLTDataset</span><br><span class="line"><span class="keyword">from</span> tools.progressively_balance <span class="keyword">import</span> ProgressiveSampler</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">setup_seed(<span class="number">12345</span>) <span class="comment"># 先固定随机种子</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析命令行的参数</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Training&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>,default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;learning rate&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--bs&#x27;</span>,default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;training batch size&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--max_epoch&#x27;</span>,default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--data_root_dir&#x27;</span>,default=<span class="string">r&quot;/Users/kenton/Downloads/deeplearning_dataset/cifar-10&quot;</span>,</span><br><span class="line">                    <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;path to your dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接收参数</span></span><br><span class="line">cfg.lr_init = args.lr <span class="keyword">if</span> args.lr <span class="keyword">else</span> cfg.lr_init</span><br><span class="line">cfg.train_bs = args.bs <span class="keyword">if</span> args.bs <span class="keyword">else</span> cfg.train_bs</span><br><span class="line">cfg.max_epoch = args.max_epoch <span class="keyword">if</span> args.bs <span class="keyword">else</span> cfg.max_epoch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># step 0: config</span></span><br><span class="line">    <span class="comment"># 数据路径</span></span><br><span class="line">    train_dir = os.path.join(args.data_root_dir, <span class="string">&quot;cifar10_train&quot;</span>)</span><br><span class="line">    valid_dir = os.path.join(args.data_root_dir, <span class="string">&quot;cifar10_test&quot;</span>)</span><br><span class="line">    <span class="comment"># path_state_dict = &quot;/Users/kenton/Downloads/deeplearning_dataset/pretrain_model/resnet18-f37072fd.pth&quot; # 预训练模型所在位置</span></span><br><span class="line">    check_data_dir(train_dir) <span class="comment"># 验证路径是否存在</span></span><br><span class="line">    check_data_dir(valid_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建logger</span></span><br><span class="line">    res_dir = os.path.join(BASE_DIR, <span class="string">&quot;..&quot;</span>, <span class="string">&quot;..&quot;</span>, <span class="string">&quot;results&quot;</span>)</span><br><span class="line">    logger, log_dir = make_logger(res_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># step 1: 数据集</span></span><br><span class="line">    <span class="comment"># 构建Dataset实例，构建DataLoader</span></span><br><span class="line">    train_data = CifarLTDataset(root_dir=train_dir, transform=cfg.transforms_train,isTrain=<span class="literal">True</span>)</span><br><span class="line">    valid_data = CifarLTDataset(root_dir=valid_dir, transform=cfg.transforms_valid,isTrain=<span class="literal">False</span>)</span><br><span class="line">    train_loader = DataLoader(dataset=train_data, batch_size=cfg.train_bs, shuffle=<span class="literal">True</span>, num_workers=cfg.workers)</span><br><span class="line">    valid_loader = DataLoader(dataset=valid_data, batch_size=cfg.valid_bs, num_workers=cfg.workers)</span><br><span class="line">    <span class="keyword">if</span> cfg.pb:</span><br><span class="line">        sampler_generator = ProgressiveSampler(train_data, cfg.max_epoch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 模型</span></span><br><span class="line">    model = resnet20()</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    # 加载预训练模型的参数 state_dict</span></span><br><span class="line"><span class="string">    if os.path.exists(path_state_dict):</span></span><br><span class="line"><span class="string">        pretrained_state_dict = torch.load(path_state_dict, map_location=&#x27;cpu&#x27;)</span></span><br><span class="line"><span class="string">        model.load_state_dict(pretrained_state_dict)</span></span><br><span class="line"><span class="string">        logger.info(&quot;Load pretrained model&quot;)</span></span><br><span class="line"><span class="string">    else:</span></span><br><span class="line"><span class="string">        logger.info(&quot;The pretrained model path &#123;&#125; is not exists&quot;.format(path_state_dict))</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    # 修改最后一层</span></span><br><span class="line"><span class="string">    num_ftrs = model.fc.in_features</span></span><br><span class="line"><span class="string">    model.fc = nn.Linear(num_ftrs, train_data.cls_num)</span></span><br><span class="line"><span class="string">    # to device</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 损失函数 优化器 等</span></span><br><span class="line">    loss_f = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=cfg.lr_init, momentum=cfg.momentum, weight_decay=cfg.weight_decay)</span><br><span class="line">    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, gamma=cfg.factor, milestones=cfg.milestones)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 迭代训练</span></span><br><span class="line">    loss_rec = &#123;<span class="string">&#x27;train&#x27;</span>:[], <span class="string">&quot;valid&quot;</span>:[]&#125;</span><br><span class="line">    acc_rec = &#123;<span class="string">&#x27;train&#x27;</span>:[], <span class="string">&quot;valid&quot;</span>:[]&#125;</span><br><span class="line">    best_acc, best_epoch = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(cfg.max_epoch):</span><br><span class="line">        <span class="keyword">if</span> cfg.pb:</span><br><span class="line">            sampler, _ = sampler_generator(epoch)</span><br><span class="line">            train_loader = DataLoader(dataset=train_data, batch_size=cfg.train_bs, shuffle=<span class="literal">False</span>,</span><br><span class="line">                                      num_workers=cfg.workers, sampler=sampler)</span><br><span class="line">        <span class="comment"># dataloader</span></span><br><span class="line">        loss_train, acc_train, mat_train, path_error_train = ModelTrainer.train(</span><br><span class="line">            train_loader, model, loss_f, optimizer, scheduler, epoch, device, cfg, logger)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># valid</span></span><br><span class="line">        loss_valid, acc_valid, mat_valid, path_error_valid = ModelTrainer.valid(</span><br><span class="line">            valid_loader, model, loss_f, device)</span><br><span class="line"></span><br><span class="line">        logger.info(<span class="string">&quot;Epoch[&#123;:0&gt;3&#125;/&#123;:0&gt;3&#125;] Train Acc:&#123;:.2%&#125; Valid Acc:&#123;:.2%&#125; Train loss:&#123;:.4f&#125; Valid loss:&#123;:.4f&#125; LR:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                cfg.max_epoch, acc_train, acc_valid, loss_train, loss_valid,</span><br><span class="line">                optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>]))</span><br><span class="line"></span><br><span class="line">        scheduler.step() <span class="comment"># 学习率进行更新！！！</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录训练信息</span></span><br><span class="line">        loss_rec[<span class="string">&quot;train&quot;</span>].append(loss_train), loss_rec[<span class="string">&quot;valid&quot;</span>].append(loss_valid)</span><br><span class="line">        acc_rec[<span class="string">&quot;train&quot;</span>].append(acc_train), acc_rec[<span class="string">&quot;valid&quot;</span>].append(acc_valid)</span><br><span class="line">        <span class="comment"># 保存混淆矩阵图</span></span><br><span class="line">        show_confMat(mat_train, train_data.names, <span class="string">&quot;train&quot;</span>, log_dir, epoch=epoch, verbose=epoch == cfg.max_epoch - <span class="number">1</span>)</span><br><span class="line">        show_confMat(mat_valid, valid_data.names, <span class="string">&quot;valid&quot;</span>, log_dir, epoch=epoch, verbose=epoch == cfg.max_epoch - <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 保存loss曲线 acc曲线</span></span><br><span class="line">        plt_x = np.arange(<span class="number">1</span>, epoch + <span class="number">2</span>)</span><br><span class="line">        plot_line(plt_x, loss_rec[<span class="string">&quot;train&quot;</span>], plt_x, loss_rec[<span class="string">&quot;valid&quot;</span>], mode=<span class="string">&quot;loss&quot;</span>, out_dir=log_dir)</span><br><span class="line">        plot_line(plt_x, acc_rec[<span class="string">&quot;train&quot;</span>], plt_x, acc_rec[<span class="string">&quot;valid&quot;</span>], mode=<span class="string">&quot;acc&quot;</span>, out_dir=log_dir)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        <span class="keyword">if</span> best_acc &lt; acc_valid <span class="keyword">or</span> epoch == cfg.max_epoch - <span class="number">1</span>:</span><br><span class="line">            best_epoch = epoch <span class="keyword">if</span> best_acc &lt; acc_valid <span class="keyword">else</span> best_epoch</span><br><span class="line">            best_acc = acc_valid <span class="keyword">if</span> best_acc &lt; acc_valid <span class="keyword">else</span> best_acc</span><br><span class="line">            checkpoint = &#123;<span class="string">&quot;model_state_dict&quot;</span>: model.state_dict(),</span><br><span class="line">                          <span class="string">&quot;optimizer_state_dict&quot;</span>: optimizer.state_dict(),</span><br><span class="line">                          <span class="string">&quot;epoch&quot;</span>: epoch,</span><br><span class="line">                          <span class="string">&quot;best_acc&quot;</span>: best_acc&#125;</span><br><span class="line">            pkl_name = <span class="string">&quot;checkpoint_&#123;&#125;.pkl&quot;</span>.<span class="built_in">format</span>(epoch) <span class="keyword">if</span> epoch == cfg.max_epoch - <span class="number">1</span> <span class="keyword">else</span> <span class="string">&quot;checkpoint_best.pkl&quot;</span></span><br><span class="line">            path_checkpoint = os.path.join(log_dir, pkl_name)</span><br><span class="line">            torch.save(checkpoint, path_checkpoint)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 保存错误图片的路径</span></span><br><span class="line">            err_ims_name = <span class="string">&quot;error_imgs_&#123;&#125;.pkl&quot;</span>.<span class="built_in">format</span>(epoch) <span class="keyword">if</span> epoch == cfg.max_epoch - <span class="number">1</span> <span class="keyword">else</span> <span class="string">&quot;error_imgs_best.pkl&quot;</span></span><br><span class="line">            path_err_img = os.path.join(log_dir, err_ims_name)</span><br><span class="line">            error_info = &#123;&#125;</span><br><span class="line">            error_info[<span class="string">&quot;train&quot;</span>] = path_error_train</span><br><span class="line">            error_info[<span class="string">&quot;valid&quot;</span>] = path_error_valid</span><br><span class="line">            pickle.dump(error_info, <span class="built_in">open</span>(path_err_img, <span class="string">&quot;wb&quot;</span>))</span><br><span class="line">    logger.info(<span class="string">&quot;&#123;&#125; done, best acc:&#123;&#125; in: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        datetime.strftime(datetime.now(), <span class="string">&quot;%m-%d_%H-%M&quot;</span>), best_acc, best_epoch))</span><br></pre></td></tr></table></figure><h2 id="实验实践"><a href="#实验实践" class="headerlink" title="实验实践"></a>实验实践</h2><p>采用PB Sampling和不采用PB Sampling时，模型精度的变化，表格如下：</p><table><thead><tr><th></th><th>Train Acc</th><th>Valid Acc</th><th>Train loss</th><th>Valid loss</th></tr></thead><tbody><tr><td>有PB Sampling</td><td>96.78%</td><td>71.25%</td><td>0.0920</td><td>1.3972</td></tr><tr><td>无PB Sampling</td><td>97.19%</td><td>68.87%</td><td>0.0821</td><td>1.6085</td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> 花朵分类项目 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「花朵分类项目」（四）模型涨点技巧</title>
      <link href="/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E5%9B%9B%EF%BC%89%E6%A8%A1%E5%9E%8B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7/"/>
      <url>/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E5%9B%9B%EF%BC%89%E6%A8%A1%E5%9E%8B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="数据增强「增广」"><a href="#数据增强「增广」" class="headerlink" title="数据增强「增广」"></a>数据增强「增广」</h2><p>数据增强指通过图像处理方法对训练集数据进行丰富化</p><p>数据增强使用原则：让训练集逼近验证集、测试集 </p><h3 id="PyTorch-Transforms的二十二个方法"><a href="#PyTorch-Transforms的二十二个方法" class="headerlink" title="PyTorch.Transforms的二十二个方法"></a>PyTorch.Transforms的二十二个方法</h3><table><thead><tr><th>名称</th><th>代码操作</th></tr></thead><tbody><tr><td><strong>裁剪</strong></td><td><strong>Crop</strong></td></tr><tr><td>中心裁剪</td><td>transforms.CenterCrop</td></tr><tr><td>随机裁剪</td><td>transforms.RandomCrop</td></tr><tr><td>随机长宽比裁剪</td><td>transforms.RandomResizedCrop</td></tr><tr><td>上下左右中心裁剪</td><td>transforms.FiveCrop</td></tr><tr><td>上下左右中心裁剪后翻转</td><td>transforms.TenCrop</td></tr><tr><td><strong>翻转和旋转</strong></td><td><strong>Flip and Rotation</strong></td></tr><tr><td>依概率 p 水平翻转</td><td>transforms.RandomHorizontalFlip(p&#x3D;0.5)</td></tr><tr><td>依概率 p 垂直翻转</td><td>transforms.RandomVerticalFlip(p&#x3D;0.5)</td></tr><tr><td>随机旋转</td><td>transforms.RandomRotation</td></tr><tr><td><strong>图像变换</strong></td><td></td></tr><tr><td>resize</td><td>transforms.Resize</td></tr><tr><td>标准化</td><td>transforms.Normalize</td></tr><tr><td>转为 tensor，并归一化至[0-1]</td><td>transforms.ToTensor</td></tr><tr><td>填充</td><td>transforms.Pad</td></tr><tr><td>修改亮度、对比度和饱和度</td><td>transforms.ColorJitter</td></tr><tr><td>转灰度图</td><td>transforms.Grayscale</td></tr><tr><td>线性变换</td><td>transforms.LinearTransformation()</td></tr><tr><td>仿射变换</td><td>transforms.RandomAffine</td></tr><tr><td>依概率 p 转为灰度图</td><td>transforms.RandomGrayscale</td></tr><tr><td>将数据转换为 PILImage</td><td>transforms.ToPILImage</td></tr><tr><td>Apply a user-defined lambda as a transform</td><td>transforms.Lambda</td></tr><tr><td><strong>对 transforms 操作，使数据增强更灵活</strong></td><td></td></tr><tr><td>从给定的一系列 transforms 中选一个进行操作</td><td>transforms.RandomChoice(transforms)</td></tr><tr><td>给一个 transform 加上概率，依概率进行操作</td><td>transforms.RandomApply(transforms, p&#x3D;0.5)</td></tr><tr><td>将 transforms 中的操作随机打乱</td><td>transforms.RandomOrder</td></tr></tbody></table><span id="more"></span><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f55c3j74j20kg0k0q3s.jpg" alt="" style="zoom: 25%;" /><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f3we9uimj20k00k0gq2.jpg"></p><h3 id="Mixup"><a href="#Mixup" class="headerlink" title="Mixup"></a>Mixup</h3><p>「<a href="https://arxiv.org/abs/1710.09412">mixup: Beyond Empirical Risk Minimization</a>」</p><p>Mixup从经验风险最小化方法(Empirical Risk Minimization, ERM)角度思考，发现问题：</p><p>网络倾向于记忆训练样本，而不是泛化；</p><p>难以抵御分布外样本，如肉眼感官没有区别的对抗样本</p><p>提出使用邻域风险最小化原则(Vicinal Risk Minimization, VRM)来解决上述问题，具体操作方法称为Mixup</p><p><strong>大道至简</strong>：将两张图片按比例混合在一起得到新图片，从而扩充数据丰富度Lambda：从Beta分布中随机采样</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f5yt7nlqj20zk04bdgp.jpg"></p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f60zmhl6j20vk07dgmu.jpg"></p><h2 id="Label-Smoothing「正则化」"><a href="#Label-Smoothing「正则化」" class="headerlink" title="Label Smoothing「正则化」"></a>Label Smoothing「正则化」</h2><p>「<a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a>」</p><p>交叉熵 $CrossEntropy$: $H(p, q)&#x3D; - \sum_{K-1}^Klog(p_k)q_k{}$衡量两个概率分布之间的差异</p><p>概率有两个性质：<strong>概率值非负</strong> 和 <strong>概率值和为1</strong></p><p>所以得到的数据可以完全依靠$Softmax$函数转化到概率分布的形式</p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f6fqcch7j20zk079wep.jpg" style="zoom:25%;" /><table><thead><tr><th>概率两个性质</th><th>Softmax操作</th></tr></thead><tbody><tr><td>概率值是非负的</td><td>取指数，实现非负</td></tr><tr><td>概率之和等于1</td><td>除以指数之和，实现和为1</td></tr></tbody></table><p>传统的One-hot编码存在过度自信的问题，导致过拟合</p><p> $q$为 $one-hot$向量 $(0,1,0,0)$</p><p>$H(p, q) &#x3D; -\sum_{K&#x3D;1}^{K}log(p_k)q_k &#x3D; -log(p_2)q_2 &#x3D; -log(p_2) * 1$</p><p>标签平滑，把One-hot中概率为1的那一项进行衰减，避免过度自信，衰减的那部分confience平均分到其它的每一个类别中</p><p>$label &#x3D; (0, 1, 0, 0)$  $label Smoothing&#x3D;(0.00033, 0.999, 0.00033, 0.00033)$</p><p>$H(p, q) &#x3D; -\sum_{K&#x3D;1}^{K}log(p_k)q_k &#x3D; -[log(p_1)q_1 + log(p_2)q_2 + log(p_3)q_3 + log(p_4)q_4]$</p><h2 id="代码补充"><a href="#代码补充" class="headerlink" title="代码补充"></a>代码补充</h2><h3 id="tools-x2F-mixup-py"><a href="#tools-x2F-mixup-py" class="headerlink" title="tools&#x2F;mixup.py"></a>tools&#x2F;mixup.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :mixup.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-10</span></span><br><span class="line"><span class="string"># @brief        :mixup功能实现 内含测试样例</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mixup_data</span>(<span class="params">x, y, alpha=<span class="number">1.0</span>, device=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return mixed inputs, pairs of targets, and lambda&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过beta分布获得lambda beta分布的参数alpha == beta 因此都是alpha</span></span><br><span class="line">    lam = np.random.beta(alpha, alpha) <span class="keyword">if</span> alpha &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取需要重叠的图片的标号</span></span><br><span class="line">    batch_size = x.size()[<span class="number">0</span>]</span><br><span class="line">    index = torch.randperm(batch_size).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># mixup</span></span><br><span class="line">    mixed_x = lam * x + (<span class="number">1</span> - lam) * x[index, :]</span><br><span class="line">    y_a, y_b = y, y[index]</span><br><span class="line">    <span class="keyword">return</span> mixed_x, y_a, y_b, lam</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mixup_criterion</span>(<span class="params">criterion, pred, y_a, y_b, lam</span>):</span><br><span class="line">    <span class="keyword">return</span> lam * criterion(pred, y_a) + (<span class="number">1</span> - lam) * criterion(pred, y_b)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> cv2</span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    path_1 = <span class="string">r&quot;/Users/kenton/Downloads/deeplearning_dataset/flower102/jpg/image_00001.jpg&quot;</span></span><br><span class="line">    path_2 = <span class="string">r&quot;/Users/kenton/Downloads/deeplearning_dataset/flower102/jpg/image_00002.jpg&quot;</span></span><br><span class="line"></span><br><span class="line">    img1 = cv2.imread(path_1)</span><br><span class="line">    img2 = cv2.imread(path_2)</span><br><span class="line">    img1 = cv2.resize(img1, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">    img2 = cv2.resize(img2, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"></span><br><span class="line">    alpha = <span class="number">1</span></span><br><span class="line">    figsize = <span class="number">15</span></span><br><span class="line">    plt.figure(figsize=(<span class="built_in">int</span>(figsize), <span class="built_in">int</span>(figsize)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">        <span class="comment"># lam = i * 0.1</span></span><br><span class="line">        lam = np.random.beta(alpha, alpha)</span><br><span class="line">        im_mixup = (img1 * lam + img2 * (<span class="number">1</span> - lam)).astype(np.uint8)</span><br><span class="line">        im_mixup = cv2.cvtColor(im_mixup, cv2.COLOR_BGR2RGB)</span><br><span class="line">        plt.subplot(<span class="number">3</span>, <span class="number">3</span>, i)</span><br><span class="line">        plt.title(<span class="string">&quot;lamda_&#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lam))</span><br><span class="line">        plt.imshow(im_mixup)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="tools-x2F-my-loss-py"><a href="#tools-x2F-my-loss-py" class="headerlink" title="tools&#x2F;my_loss.py"></a>tools&#x2F;my_loss.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :my_loss.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-10</span></span><br><span class="line"><span class="string"># @brief        :重写的loss函数</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABC</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LabelSmoothLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, smoothing = <span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LabelSmoothLoss, self).__init__()</span><br><span class="line">        self.smoothing = smoothing</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, target</span>):</span><br><span class="line">        log_prob = F.log_softmax(<span class="built_in">input</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        weight = <span class="built_in">input</span>.new_ones(<span class="built_in">input</span>.size()) * self.smoothing / (<span class="built_in">input</span>.size(-<span class="number">1</span>) - <span class="number">1.</span>)</span><br><span class="line">        weight.scatter_(-<span class="number">1</span>, target.unsqueeze(-<span class="number">1</span>), (<span class="number">1</span> - self.smoothing))</span><br><span class="line">        loss = (-weight * log_prob).<span class="built_in">sum</span>(dim=-<span class="number">1</span>).mean()</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    output = torch.tensor([[<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">10.0</span>], [<span class="number">1.0</span>, <span class="number">5.0</span>, <span class="number">4.0</span>], [<span class="number">1.0</span>, <span class="number">15.0</span>, <span class="number">4.0</span>]])</span><br><span class="line">    label = torch.tensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>], dtype=torch.int64)</span><br><span class="line"></span><br><span class="line">    criterion = LabelSmoothLoss(<span class="number">0.001</span>)</span><br><span class="line">    loss = criterion(output, label)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;CrossEntropy:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(loss))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 花朵分类项目 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「花朵分类项目」（三）卷积神经网络模型</title>
      <link href="/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E4%B8%89%EF%BC%89%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"/>
      <url>/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E4%B8%89%EF%BC%89%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="VGG-ResNet-SENet介绍"><a href="#VGG-ResNet-SENet介绍" class="headerlink" title="VGG ResNet SENet介绍"></a>VGG ResNet SENet介绍</h2><h2 id="输入尺寸的选择"><a href="#输入尺寸的选择" class="headerlink" title="输入尺寸的选择"></a>输入尺寸的选择</h2><h3 id="方法一：让数据适应模型"><a href="#方法一：让数据适应模型" class="headerlink" title="方法一：让数据适应模型"></a>方法一：让数据适应模型</h3><p>直接将图像缩放&#x2F;裁剪到模型要求的输入尺寸，常见的尺寸如基于ImageNet设计的如224*224系列、基于Cifar设计的32*32系列</p><h3 id="方法二：修改模型适应参数"><a href="#方法二：修改模型适应参数" class="headerlink" title="方法二：修改模型适应参数"></a>方法二：修改模型适应参数</h3><p>修改分辨率下降的地方，以改变模型对输入尺寸的要求删除一个Pooling，使224*224变为可接收112*112增加一个Pooling，使224*224变为可接收448*448卷积步长stride&#x3D;2的，改为stide&#x3D;1，使输入可变为112*112卷积步长stride&#x3D;1的，改为stide&#x3D;2，使输入可变为448*448自行设计卷积核大小，stride，池化层数量</p><span id="more"></span><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f0prhgq1j208w0zkmza.jpg" style="zoom:25%;" /><h3 id="方法三：划分成Patch形式，分别处理，如遥感影像、数字病理图像"><a href="#方法三：划分成Patch形式，分别处理，如遥感影像、数字病理图像" class="headerlink" title="方法三：划分成Patch形式，分别处理，如遥感影像、数字病理图像"></a>方法三：划分成Patch形式，分别处理，如遥感影像、数字病理图像</h3><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2f0pbom0jj20zk0by769.jpg"></p><h2 id="代码优化"><a href="#代码优化" class="headerlink" title="代码优化"></a>代码优化</h2><h3 id="models-x2F-vgg-tv-py"><a href="#models-x2F-vgg-tv-py" class="headerlink" title="models&#x2F;vgg_tv.py"></a>models&#x2F;vgg_tv.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.model_zoo <span class="keyword">as</span> model_zoo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">__all__ = [</span><br><span class="line">    <span class="string">&#x27;VGG&#x27;</span>, <span class="string">&#x27;vgg11&#x27;</span>, <span class="string">&#x27;vgg11_bn&#x27;</span>, <span class="string">&#x27;vgg13&#x27;</span>, <span class="string">&#x27;vgg13_bn&#x27;</span>, <span class="string">&#x27;vgg16&#x27;</span>, <span class="string">&#x27;vgg16_bn&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg19_bn&#x27;</span>, <span class="string">&#x27;vgg19&#x27;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_urls = &#123;</span><br><span class="line">    <span class="string">&#x27;vgg11&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg11-bbd30ac9.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg13&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg13-c768596a.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg16&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg16-397923af.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg19&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg11_bn&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg11_bn-6002323d.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg13_bn&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg13_bn-abd245e5.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg16_bn&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg16_bn-6c64b313.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;vgg19_bn&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/vgg19_bn-c79401a0.pth&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGG</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, num_classes=<span class="number">1000</span>, init_weights=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(VGG, self).__init__()</span><br><span class="line">        self.features = features</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># self.xxx = nn.XXXX</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_weights</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                nn.init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_layers</span>(<span class="params">cfg, batch_norm=<span class="literal">False</span></span>):</span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&#x27;M&#x27;</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cfg = &#123;</span><br><span class="line">    <span class="string">&#x27;A&#x27;</span>: [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;B&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;E&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg11</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;VGG 11-layer model (configuration &quot;A&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        kwargs[<span class="string">&#x27;init_weights&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">&#x27;A&#x27;</span>]), **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;vgg11&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg11_bn</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;VGG 11-layer model (configuration &quot;A&quot;) with batch normalization</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        kwargs[<span class="string">&#x27;init_weights&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">&#x27;A&#x27;</span>], batch_norm=<span class="literal">True</span>), **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;vgg11_bn&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg13</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;VGG 13-layer model (configuration &quot;B&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        kwargs[<span class="string">&#x27;init_weights&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">&#x27;B&#x27;</span>]), **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;vgg13&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg13_bn</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;VGG 13-layer model (configuration &quot;B&quot;) with batch normalization</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        kwargs[<span class="string">&#x27;init_weights&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">&#x27;B&#x27;</span>], batch_norm=<span class="literal">True</span>), **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;vgg13_bn&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg16</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;VGG 16-layer model (configuration &quot;D&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        kwargs[<span class="string">&#x27;init_weights&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">&#x27;D&#x27;</span>]), **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;vgg16&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg16_bn</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;VGG 16-layer model (configuration &quot;D&quot;) with batch normalization</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        kwargs[<span class="string">&#x27;init_weights&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">&#x27;D&#x27;</span>], batch_norm=<span class="literal">True</span>), **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;vgg16_bn&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg19</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;VGG 19-layer model (configuration &quot;E&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        kwargs[<span class="string">&#x27;init_weights&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">&#x27;E&#x27;</span>]), **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;vgg19&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg19_bn</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;VGG 19-layer model (configuration &#x27;E&#x27;) with batch normalization</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        kwargs[<span class="string">&#x27;init_weights&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">&#x27;E&#x27;</span>], batch_norm=<span class="literal">True</span>), **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;vgg19_bn&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    model = vgg16_bn()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 替换网络层</span></span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> model.named_modules():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;layer name:&#123;&#125;, layer instance:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(name, module))</span><br><span class="line">    in_feat_num = model.classifier[<span class="number">6</span>].in_features</span><br><span class="line">    model.classifier[<span class="number">6</span>] = nn.Linear(in_feat_num, <span class="number">102</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    fake_img = torch.randn((<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))  <span class="comment"># batchsize * channel * height * width</span></span><br><span class="line">    output = model(fake_img)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure><h3 id="models-x2F-resnet-tv-py"><a href="#models-x2F-resnet-tv-py" class="headerlink" title="models&#x2F;resnet_tv.py"></a>models&#x2F;resnet_tv.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.model_zoo <span class="keyword">as</span> model_zoo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">__all__ = [<span class="string">&#x27;ResNet&#x27;</span>, <span class="string">&#x27;resnet18&#x27;</span>, <span class="string">&#x27;resnet34&#x27;</span>, <span class="string">&#x27;resnet50&#x27;</span>, <span class="string">&#x27;resnet101&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;resnet152&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_urls = &#123;</span><br><span class="line">    <span class="string">&#x27;resnet18&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/resnet18-5c106cde.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;resnet34&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;resnet50&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/resnet50-19c8e357.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;resnet101&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/resnet101-5d3b4d8f.pth&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;resnet152&#x27;</span>: <span class="string">&#x27;https://download.pytorch.org/models/resnet152-b121ed2d.pth&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv3x3</span>(<span class="params">in_planes, out_planes, stride=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;3x3 convolution with padding&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                     padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv1x1</span>(<span class="params">in_planes, out_planes, stride=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;1x1 convolution&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line">        self.conv1 = conv1x1(inplanes, planes)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes, stride)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv3 = conv1x1(planes, planes * self.expansion)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(planes * self.expansion)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, layers, num_classes=<span class="number">1000</span>, zero_init_residual=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.inplanes = <span class="number">64</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>,</span><br><span class="line">                               bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">64</span>, layers[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, layers[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, layers[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, layers[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                nn.init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Zero-initialize the last BN in each residual branch,</span></span><br><span class="line">        <span class="comment"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span></span><br><span class="line">        <span class="comment"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span></span><br><span class="line">        <span class="keyword">if</span> zero_init_residual:</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, Bottleneck):</span><br><span class="line">                    nn.init.constant_(m.bn3.weight, <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, BasicBlock):</span><br><span class="line">                    nn.init.constant_(m.bn2.weight, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, planes, blocks, stride=<span class="number">1</span></span>):</span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                conv1x1(self.inplanes, planes * block.expansion, stride),</span><br><span class="line">                nn.BatchNorm2d(planes * block.expansion),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.inplanes, planes, stride, downsample))</span><br><span class="line">        self.inplanes = planes * block.expansion</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, blocks):</span><br><span class="line">            layers.append(block(self.inplanes, planes))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet18</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-18 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(BasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;resnet18&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet34</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-34 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;resnet34&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet50</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-50 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;resnet50&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet101</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-101 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;resnet101&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet152</span>(<span class="params">pretrained=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-152 model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(Bottleneck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;resnet152&#x27;</span>]))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> torch</span><br><span class="line">    model = resnet18(pretrained=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 替换网络层</span></span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> model.named_modules():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;layer name:&#123;&#125;, layer instance:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(name, module))</span><br><span class="line">    in_feat_num = model.fc.in_features</span><br><span class="line">    model.fc = nn.Linear(in_feat_num, <span class="number">102</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    fake_img = torch.randn((<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))  <span class="comment"># batchsize * channel * height * width</span></span><br><span class="line">    output = model(fake_img)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure><h3 id="models-x2F-se-resnet-py"><a href="#models-x2F-se-resnet-py" class="headerlink" title="models&#x2F;se_resnet.py"></a>models&#x2F;se_resnet.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.hub <span class="keyword">import</span> load_state_dict_from_url</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> ResNet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SELayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, channel, reduction=<span class="number">16</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SELayer, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)     <span class="comment"># squeeze</span></span><br><span class="line">        self.fc = nn.Sequential(                    <span class="comment"># excitation</span></span><br><span class="line">            nn.Linear(channel, channel // reduction, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(channel // reduction, channel, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        y = self.avg_pool(x).view(b, c)</span><br><span class="line">        y = self.fc(y).view(b, c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x * y.expand_as(x)  <span class="comment"># expand_as把一个tensor变成和函数括号内一样形状的tensor</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv3x3</span>(<span class="params">in_planes, out_planes, stride=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SEBasicBlock</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>, groups=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 *, reduction=<span class="number">16</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SEBasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes, <span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.se = SELayer(planes, reduction)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        residual = x</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.se(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += residual</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SEBottleneck</span>(nn.Module):</span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span>, groups=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 *, reduction=<span class="number">16</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SEBottleneck, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                               padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.conv3 = nn.Conv2d(planes, planes * <span class="number">4</span>, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(planes * <span class="number">4</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.se = SELayer(planes * <span class="number">4</span>, reduction)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        residual = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line">        out = self.se(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += residual</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">se_resnet18</span>(<span class="params">num_classes=<span class="number">1_000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-18 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(SEBasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], num_classes=num_classes)</span><br><span class="line">    model.avgpool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">se_resnet34</span>(<span class="params">num_classes=<span class="number">1_000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-34 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(SEBasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes)</span><br><span class="line">    model.avgpool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">se_resnet50</span>(<span class="params">num_classes=<span class="number">1_000</span>, pretrained=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-50 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(SEBottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], num_classes=num_classes)</span><br><span class="line">    model.avgpool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(load_state_dict_from_url(</span><br><span class="line">            <span class="string">&quot;https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl&quot;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">se_resnet101</span>(<span class="params">num_classes=<span class="number">1_000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-101 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(SEBottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], num_classes=num_classes)</span><br><span class="line">    model.avgpool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">se_resnet152</span>(<span class="params">num_classes=<span class="number">1_000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-152 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(SEBottleneck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>], num_classes=num_classes)</span><br><span class="line">    model.avgpool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> torch</span><br><span class="line">    model = se_resnet50()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 替换网络层</span></span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> model.named_modules():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;layer name:&#123;&#125;, layer instance:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(name, module))</span><br><span class="line">    in_feat_num = model.fc.in_features</span><br><span class="line">    model.fc = nn.Linear(in_feat_num, <span class="number">102</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    fake_img = torch.randn((<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))  <span class="comment"># batchsize * channel * height * width</span></span><br><span class="line">    output = model(fake_img)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure><h2 id="图片处理展示「ResNet」"><a href="#图片处理展示「ResNet」" class="headerlink" title="图片处理展示「ResNet」"></a>图片处理展示「ResNet」</h2><table><thead><tr><th>步骤</th><th>经过何种操作</th><th>数据类型</th><th>数据形状「batch_size&#x3D;16」</th></tr></thead><tbody><tr><td>1</td><td>Image.open</td><td>PIL.image</td><td>(666,500,3)</td></tr><tr><td>2</td><td>Transforms.Compose</td><td>tensor</td><td>(3,224,224)</td></tr><tr><td>3</td><td>Model(inputs):输入模型</td><td>tensor</td><td>(16,3,224,224)</td></tr><tr><td>4</td><td>Resnet: conv1</td><td>tensor</td><td>(16,64,112,112)</td></tr><tr><td>5</td><td>Resnet: bn1</td><td>tensor</td><td>(16,64,112,112)</td></tr><tr><td>6</td><td>Resnet:relu</td><td>tensor</td><td>(16,64,112,112)</td></tr><tr><td>7</td><td>Resnet:maxpool</td><td>tensor</td><td>(16,64,56,56)</td></tr><tr><td>5</td><td>Resnet: layer1</td><td>tensor</td><td>(16,64,56,56)</td></tr><tr><td>6</td><td>Resnet: layer2</td><td>tensor</td><td>(16,128,28,28)</td></tr><tr><td>7</td><td>Resnet: layer3</td><td>tensor</td><td>(16,256,14,14)</td></tr><tr><td>8</td><td>Resnet: layer4</td><td>tensor</td><td>(16,512,7,7)</td></tr><tr><td>9</td><td>Resnet: avgpool</td><td>tensor</td><td>(16,512,1,1)</td></tr><tr><td>10</td><td>Resnet: flatten</td><td>tensor</td><td>(16,512)</td></tr><tr><td>11</td><td>Resnet: fc</td><td>tensor</td><td>(16,102)</td></tr><tr><td>12</td><td>x</td><td>tensor</td><td>(16,102)</td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> 花朵分类项目 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「花朵分类项目」（二）功能函数</title>
      <link href="/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E4%BA%8C%EF%BC%89%E5%8A%9F%E8%83%BD%E5%87%BD%E6%95%B0%E4%BB%8B%E7%BB%8D/"/>
      <url>/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E4%BA%8C%EF%BC%89%E5%8A%9F%E8%83%BD%E5%87%BD%E6%95%B0%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="模型训练指标"><a href="#模型训练指标" class="headerlink" title="模型训练指标"></a>模型训练指标</h2><table><thead><tr><th>指标</th><th>内容</th></tr></thead><tbody><tr><td>正确率(Accuracy)</td><td>衡量模型在整个数据集上分类正确的比例</td></tr><tr><td>召回率(Recall)</td><td>该类样本中，召回（找回）出了多少</td></tr><tr><td>精确度(Precision)</td><td>判别为该类的样本中，正确的有多少</td></tr><tr><td>混淆矩阵(Confusion Matrix)</td><td>混淆矩阵的<strong>行</strong>表示真实类别，<strong>列</strong>表示预测类别</td></tr></tbody></table><table><thead><tr><th>「混淆矩阵」</th><th>猫「预测类别」</th><th>狗「预测类别」</th></tr></thead><tbody><tr><td><strong>猫「真实类别」</strong></td><td>7</td><td>3</td></tr><tr><td><strong>狗「真实类别」</strong></td><td>10</td><td>20</td></tr></tbody></table><table><thead><tr><th>召回率</th><th>精确度</th></tr></thead><tbody><tr><td>猫「7&#x2F;(7+3)&#x3D;70%」狗「20&#x2F;(10+20)&#x3D;66.7%」</td><td>猫「7&#x2F;(7+10)&#x3D;41.17%」狗「20&#x2F;(3+20)&#x3D;86.96%」</td></tr></tbody></table><span id="more"></span><h2 id="模型选择方法"><a href="#模型选择方法" class="headerlink" title="模型选择方法"></a>模型选择方法</h2><p>模型选择泛化性能好的「<strong>方差低、偏差也小</strong>」</p><p>误差分解为：<strong>偏差</strong>，<strong>方差</strong>和<strong>噪声</strong>之和</p><p><strong>偏差</strong>度量算法的<strong>期望预测</strong>与<strong>真实结果</strong>的<strong>偏离程度</strong>，即刻画了算法本身的<strong>拟合能力</strong></p><p><strong>方差</strong>度量同样大小的<strong>训练集的变动</strong>所导致的<strong>学习性能的变化</strong>，即刻画了<strong>数据扰动所造成的影响</strong></p><p><strong>噪声</strong>则表达了在当前任务上任何学习算法所能达到的<strong>期望泛化误差的下界</strong></p><h2 id="代码优化"><a href="#代码优化" class="headerlink" title="代码优化"></a>代码优化</h2><h3 id="tools-x2F-common-tool-py"><a href="#tools-x2F-common-tool-py" class="headerlink" title="tools&#x2F;common_tool.py"></a>tools&#x2F;common_tool.py</h3><p>随机种子：setup_seed()</p><p>logging：采用logging模块进行日志信息记录</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :common_tools.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-2</span></span><br><span class="line"><span class="string"># @brief        :常用文件 包含随机种子固定/检查数据目录/Logger类/绘制混淆矩阵/绘制loss和acc曲线</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> psutil</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> models.vgg_tv <span class="keyword">import</span> vgg16_bn</span><br><span class="line"><span class="keyword">from</span> models.se_resnet <span class="keyword">import</span> se_resnet50</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup_seed</span>(<span class="params">seed = <span class="number">12345</span></span>):</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed) <span class="comment"># cpu</span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed_all(seed) <span class="comment"># cuda也有一个random</span></span><br><span class="line">        torch.backends.cudnn.determinstic = <span class="literal">True</span></span><br><span class="line">        torch.backends.cudnn.benchmark = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_data_dir</span>(<span class="params">path_tmp</span>):</span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(path_tmp), \</span><br><span class="line">        <span class="string">&quot;\n\n路径不存在，当前变量中指定的路径是：\n&#123;&#125;\n请检查相对路径的设置，或者文件是否存在&quot;</span>.<span class="built_in">format</span>(os.path.abspath)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Logger</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path_log</span>):</span><br><span class="line">        log_name = os.path.basename(path_log)</span><br><span class="line">        self.log_name = log_name <span class="keyword">if</span> log_name <span class="keyword">else</span> <span class="string">&quot;root&quot;</span></span><br><span class="line">        self.out_path = path_log</span><br><span class="line"></span><br><span class="line">        log_dir = os.path.dirname(self.out_path)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(log_dir):</span><br><span class="line">            os.makedirs(log_dir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_logger</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化</span></span><br><span class="line">        logger = logging.getLogger(self.log_name)</span><br><span class="line">        logger.setLevel(level=logging.INFO)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置文件Header 输出到硬盘当中</span></span><br><span class="line">        file_handler = logging.FileHandler(self.out_path, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">        file_handler.setLevel(logging.INFO)</span><br><span class="line">        formatter = logging.Formatter(<span class="string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span>)</span><br><span class="line">        file_handler.setFormatter(formatter)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置文件Header 输出到屏幕流上</span></span><br><span class="line">        console_handler = logging.StreamHandler()</span><br><span class="line">        console_handler.setLevel(logging.INFO)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 添加handler</span></span><br><span class="line">        logger.addHandler(file_handler)</span><br><span class="line">        logger.addHandler(console_handler)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logger</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_logger</span>(<span class="params">out_dir</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    在out_dir文件夹下以当前时间命名，创建日志文件夹，并创建logger用于记录信息</span></span><br><span class="line"><span class="string">    :param out_dir:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 创建log文件夹</span></span><br><span class="line">    now_time = datetime.now()</span><br><span class="line">    time_str = datetime.strftime(now_time, <span class="string">&#x27;%m-%d_%H-%M&#x27;</span>)</span><br><span class="line">    log_dir = os.path.join(out_dir, <span class="string">&quot;..&quot;</span>, <span class="string">&quot;..&quot;</span>, <span class="string">&quot;results&quot;</span>, time_str) <span class="comment"># 为了相对路径一定找的准确</span></span><br><span class="line">        <span class="comment"># 根据config中的创建时间作为文件夹名字</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(log_dir):</span><br><span class="line">        os.makedirs((log_dir))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建logger</span></span><br><span class="line">    path_log = os.path.join(log_dir, <span class="string">&quot;log.log&quot;</span>)</span><br><span class="line">    logger = Logger(path_log)</span><br><span class="line">    logger = logger.init_logger()</span><br><span class="line">    <span class="keyword">return</span> logger,log_dir</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_model</span>(<span class="params">cfg, cls_num, logger</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    创建模型</span></span><br><span class="line"><span class="string">    :param cfg:</span></span><br><span class="line"><span class="string">    :param cls_num:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> cfg.model_name == <span class="string">&quot;resnet18&quot;</span>:</span><br><span class="line">        model = resnet18()</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(cfg.path_resnet18):</span><br><span class="line">            pretrained_state_dict = torch.load(cfg.path_resnet18, map_location=<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">            model.load_state_dict(pretrained_state_dict)    <span class="comment"># load pretrain model</span></span><br><span class="line">            logger.info(<span class="string">&quot;load pretrained model!&quot;</span>)</span><br><span class="line">        <span class="comment"># 修改最后一层</span></span><br><span class="line">        num_ftrs = model.fc.in_features</span><br><span class="line">        model.fc = nn.Linear(num_ftrs, cls_num)  <span class="comment"># 102</span></span><br><span class="line">    <span class="keyword">elif</span> cfg.model_name == <span class="string">&quot;vgg16_bn&quot;</span>:</span><br><span class="line">        model = vgg16_bn()</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(cfg.path_vgg16bn):</span><br><span class="line">            pretrained_state_dict = torch.load(cfg.path_vgg16bn, map_location=<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">            model.load_state_dict(pretrained_state_dict)    <span class="comment"># load pretrain model</span></span><br><span class="line">            logger.info(<span class="string">&quot;load pretrained model!&quot;</span>)</span><br><span class="line">        <span class="comment"># 替换网络层</span></span><br><span class="line">        in_feat_num = model.classifier[<span class="number">6</span>].in_features</span><br><span class="line">        model.classifier[<span class="number">6</span>] = nn.Linear(in_feat_num, cls_num)</span><br><span class="line">    <span class="keyword">elif</span> cfg.model_name == <span class="string">&quot;se_resnet50&quot;</span>:</span><br><span class="line">        model = se_resnet50()</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(cfg.path_se_res50):</span><br><span class="line">            model.load_state_dict(torch.load(cfg.path_se_res50))    <span class="comment"># load pretrain model</span></span><br><span class="line">            logger.info(<span class="string">&quot;load pretrained model!&quot;</span>)</span><br><span class="line">        in_feat_num = model.fc.in_features</span><br><span class="line">        model.fc = nn.Linear(in_feat_num, cls_num)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">&quot;Invalid model name. got &#123;&#125;&quot;</span>.<span class="built_in">format</span>(cfg.model_name))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_confMat</span>(<span class="params">confusion_mat, classes, set_name, out_dir, epoch=<span class="number">999</span>, verbose=<span class="literal">False</span>, figsize=<span class="literal">None</span>, perc=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    混淆矩阵绘制并保存图片</span></span><br><span class="line"><span class="string">    :param confusion_mat: np.array</span></span><br><span class="line"><span class="string">    :param classes: list or tuple, 类别名称</span></span><br><span class="line"><span class="string">    :param set_name: str 数据集名称 train or valid or test</span></span><br><span class="line"><span class="string">    :param out_dir: str 图片要保存的文件夹</span></span><br><span class="line"><span class="string">    :param epoch: int 第几个epoch</span></span><br><span class="line"><span class="string">    :param verbose: bool 是否打印精度信息</span></span><br><span class="line"><span class="string">    :param figsize:</span></span><br><span class="line"><span class="string">    :param perc:是否采用百分比，图像分割时使用 因分类数目过大</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    cls_num = <span class="built_in">len</span>(classes)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 归一化</span></span><br><span class="line">    confusion_mat_tmp = confusion_mat.copy()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes)):</span><br><span class="line">        confusion_mat_tmp[i, :] = confusion_mat[i, :] / confusion_mat[i, :].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置图像大小</span></span><br><span class="line">    <span class="keyword">if</span> cls_num &lt; <span class="number">10</span>:</span><br><span class="line">        figsize = <span class="number">6</span></span><br><span class="line">    <span class="keyword">elif</span> cls_num &gt;= <span class="number">100</span>:</span><br><span class="line">        figsize = <span class="number">30</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        figsize = np.linspace(<span class="number">6</span>, <span class="number">30</span>, <span class="number">91</span>)[cls_num-<span class="number">10</span>]</span><br><span class="line">    plt.figure(figsize=(<span class="built_in">int</span>(figsize), <span class="built_in">int</span>(figsize*<span class="number">1.3</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取颜色</span></span><br><span class="line">    cmap = plt.cm.get_cmap(<span class="string">&#x27;Greys&#x27;</span>) <span class="comment"># 更多颜色: http://matplotlib.org/examples/color/colormaps_reference.html</span></span><br><span class="line">    plt.imshow(confusion_mat_tmp, cmap=cmap)</span><br><span class="line">    plt.colorbar(fraction=<span class="number">0.03</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置文字</span></span><br><span class="line">    xlocations = np.array(<span class="built_in">range</span>(<span class="built_in">len</span>(classes)))</span><br><span class="line">    plt.xticks(xlocations, <span class="built_in">list</span>(classes), rotation=<span class="number">60</span>)</span><br><span class="line">    plt.yticks(xlocations, <span class="built_in">list</span>(classes))</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Predict label&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;Confusion_Matrix_&#123;&#125;_&#123;&#125;&quot;</span>.<span class="built_in">format</span>(set_name, epoch))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印数字</span></span><br><span class="line">    <span class="keyword">if</span> perc:</span><br><span class="line">        cls_per_nums = confusion_mat.<span class="built_in">sum</span>(axis=<span class="number">0</span>)</span><br><span class="line">        conf_mat_per = confusion_mat / cls_per_nums</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(confusion_mat_tmp.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(confusion_mat_tmp.shape[<span class="number">1</span>]):</span><br><span class="line">                plt.text(x=j, y=i, s=<span class="string">&quot;&#123;:.0%&#125;&quot;</span>.<span class="built_in">format</span>(conf_mat_per[i, j]), va=<span class="string">&#x27;center&#x27;</span>, ha=<span class="string">&#x27;center&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">                         fontsize=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(confusion_mat_tmp.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(confusion_mat_tmp.shape[<span class="number">1</span>]):</span><br><span class="line">                    plt.text(x=j, y=i, s=<span class="built_in">int</span>(confusion_mat[i, j]), va=<span class="string">&#x27;center&#x27;</span>, ha=<span class="string">&#x27;center&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 保存</span></span><br><span class="line">    plt.savefig(os.path.join(out_dir, <span class="string">&quot;Confusion_Matrix_&#123;&#125;.png&quot;</span>).<span class="built_in">format</span>(set_name))</span><br><span class="line">    plt.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cls_num):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;class:&#123;:&lt;10&#125;, total num:&#123;:&lt;6&#125;, correct num:&#123;:&lt;5&#125;  Recall: &#123;:.2%&#125; Precision: &#123;:.2%&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                classes[i], np.<span class="built_in">sum</span>(confusion_mat[i, :]), confusion_mat[i, i],</span><br><span class="line">                confusion_mat[i, i] / (<span class="number">1e-9</span> + np.<span class="built_in">sum</span>(confusion_mat[i, :])),</span><br><span class="line">                confusion_mat[i, i] / (<span class="number">1e-9</span> + np.<span class="built_in">sum</span>(confusion_mat[:, i]))))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_line</span>(<span class="params">train_x, train_y, valid_x, valid_y, mode, out_dir</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制训练和验证集的loss曲线和acc曲线</span></span><br><span class="line"><span class="string">    :param train_x: epoch</span></span><br><span class="line"><span class="string">    :param train_y: 标量值</span></span><br><span class="line"><span class="string">    :param valid_x:</span></span><br><span class="line"><span class="string">    :param valid_y:</span></span><br><span class="line"><span class="string">    :param mode: &#x27;loss&#x27; or &#x27;acc&#x27;</span></span><br><span class="line"><span class="string">    :param out_dir:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    plt.plot(train_x, train_y, label=<span class="string">&#x27;Train&#x27;</span>)</span><br><span class="line">    plt.plot(valid_x, valid_y, label=<span class="string">&#x27;Valid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.ylabel(<span class="built_in">str</span>(mode))</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    location = <span class="string">&#x27;upper right&#x27;</span> <span class="keyword">if</span> mode == <span class="string">&#x27;loss&#x27;</span> <span class="keyword">else</span> <span class="string">&#x27;upper left&#x27;</span></span><br><span class="line">    plt.legend(loc=location)</span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">&#x27;_&#x27;</span>.join([mode]))</span><br><span class="line">    plt.savefig(os.path.join(out_dir, mode + <span class="string">&#x27;.png&#x27;</span>))</span><br><span class="line">    plt.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># setup_seed(2)</span></span><br><span class="line">    <span class="comment"># print(np.random.randint(0, 10, 1))</span></span><br><span class="line">    logger = Logger(<span class="string">&#x27;./logtest.log&#x27;</span>)</span><br><span class="line">    logger = logger.init_logger()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        logger.info(<span class="string">&#x27;test:&#x27;</span> + <span class="built_in">str</span>(i))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> config.flower_config <span class="keyword">import</span> cfg</span><br><span class="line">    logger.info(cfg)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="config-x2F-flower-config-py"><a href="#config-x2F-flower-config-py" class="headerlink" title="config&#x2F;flower_config.py"></a>config&#x2F;flower_config.py</h3><p>提取要配置的参数，统一放置：config&#x2F;flower_config.py中的字典</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :flower_config.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-5</span></span><br><span class="line"><span class="string"># @brief        :花朵分类网络参数配置</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets.flower102 <span class="keyword">import</span> FlowerDataset</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> easydict <span class="keyword">import</span> EasyDict</span><br><span class="line">BASE_DIR = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line">sys.path.append(os.path.join(BASE_DIR, <span class="string">&#x27;..&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cfg = EasyDict() <span class="comment"># 访问属性的方式去使用key-value 即通过key 或者 value</span></span><br><span class="line"></span><br><span class="line">cfg.model_name = <span class="string">&quot;resnet18&quot;</span></span><br><span class="line"><span class="comment"># cfg.model_name = &quot;vgg16_bn&quot;</span></span><br><span class="line"><span class="comment"># cfg.model_name = &quot;se_resnet50&quot;</span></span><br><span class="line"></span><br><span class="line">cfg.mixup = <span class="literal">True</span>  <span class="comment"># 是否采用mixup</span></span><br><span class="line">cfg.mixup_alpha = <span class="number">1.</span>  <span class="comment"># beta分布的参数. beta分布是一组定义在(0,1) 区间的连续概率分布。</span></span><br><span class="line">cfg.label_smooth = <span class="literal">True</span>  <span class="comment"># 是否采用标签平滑</span></span><br><span class="line">cfg.label_smooth_eps = <span class="number">0.01</span>  <span class="comment"># 标签平滑超参数 eps</span></span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&quot;/Users/kenton/Downloads/deeplearning_dataset&quot;</span></span><br><span class="line">cfg.path_resnet18 = os.path.join(data_dir, <span class="string">&quot;pretrained_model&quot;</span>, <span class="string">&quot;resnet18-f37072fd.pth&quot;</span>)</span><br><span class="line">cfg.path_vgg16bn = os.path.join(data_dir, <span class="string">&quot;pretrained_model&quot;</span>, <span class="string">&quot;vgg16_bn-6c64b313.pth&quot;</span>)</span><br><span class="line">cfg.path_se_res50 = os.path.join(data_dir, <span class="string">&quot;pretrained_model&quot;</span>, <span class="string">&quot;seresnet50-60a8950a85b2b.pkl&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练参数</span></span><br><span class="line">cfg.train_bs = <span class="number">16</span> <span class="comment"># batchsize</span></span><br><span class="line">cfg.valid_bs = <span class="number">16</span></span><br><span class="line">cfg.workers = <span class="number">0</span> <span class="comment">#线程个数</span></span><br><span class="line"></span><br><span class="line">cfg.lr_init = <span class="number">0.01</span></span><br><span class="line">cfg.momentum = <span class="number">0.9</span></span><br><span class="line">cfg.weight_decay = <span class="number">1e-4</span> <span class="comment"># 权重衰减</span></span><br><span class="line"></span><br><span class="line">cfg.factor = <span class="number">0.1</span> <span class="comment"># 权重更新的比例</span></span><br><span class="line">cfg.milestones = [<span class="number">30</span>, <span class="number">45</span>] <span class="comment"># 什么时候下降学习率</span></span><br><span class="line">cfg.max_epoch = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">cfg.log_interval = <span class="number">10</span> <span class="comment"># 日志打印间隔</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 数据集</span></span><br><span class="line">norm_mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">norm_std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>] <span class="comment"># imageNet统计得到的</span></span><br><span class="line">normTransform = transforms.Normalize(norm_mean, norm_std)</span><br><span class="line"></span><br><span class="line">cfg.transforms_train = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">256</span>)),</span><br><span class="line">    transforms.CenterCrop(<span class="number">256</span>),</span><br><span class="line">    transforms.RandomCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    normTransform,</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">cfg.transforms_valid = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    normTransform,</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h3 id="bin-x2F-evaluate-flower-py"><a href="#bin-x2F-evaluate-flower-py" class="headerlink" title="bin&#x2F;evaluate_flower.py"></a>bin&#x2F;evaluate_flower.py</h3><p>模型评估，在test数据集上跑模型得到最后的指标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :evaluate_flower.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-5</span></span><br><span class="line"><span class="string"># @brief        :模型在test上进行指标计算 输出结果为test acc 「0%～100%」</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> datasets.flower102 <span class="keyword">import</span> FlowerDataset</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 0. config</span></span><br><span class="line">    data_dir = <span class="string">&quot;/Users/kenton/Downloads/deeplearning_dataset/flower102/test&quot;</span></span><br><span class="line">    path_state_dir = <span class="string">&quot;/Users/kenton/PycharmProjects/results/04-05_23-40/checkpoint_best.pkl&quot;</span></span><br><span class="line"></span><br><span class="line">    norm_mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]  <span class="comment"># imagenet 120万图像统计得来</span></span><br><span class="line">    norm_std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">    normTransform = transforms.Normalize(norm_mean, norm_std)</span><br><span class="line">    transforms_valid = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        normTransform,</span><br><span class="line">    ])</span><br><span class="line">    valid_bs = <span class="number">64</span></span><br><span class="line">    workers = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># step1: dataset</span></span><br><span class="line">    test_data = FlowerDataset(root_dir=data_dir, transform=transforms_valid)</span><br><span class="line">    test_loader = DataLoader(dataset=test_data, batch_size=valid_bs, num_workers=workers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># step2: model</span></span><br><span class="line">    model = resnet18()</span><br><span class="line">    num_ftrs = model.fc.in_features</span><br><span class="line">    model.fc = nn.Linear(num_ftrs, test_data.cls_num)  <span class="comment"># 102</span></span><br><span class="line">    <span class="comment"># load pretrain model</span></span><br><span class="line">    ckpt = torch.load(path_state_dir)</span><br><span class="line">    model.load_state_dict(ckpt[<span class="string">&quot;model_state_dict&quot;</span>])</span><br><span class="line">    model.to(device)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># step 3:inference</span></span><br><span class="line">    class_num = test_loader.dataset.cls_num</span><br><span class="line">    conf_mat = np.zeros((class_num, class_num))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">        inputs, labels, path_imgs = data</span><br><span class="line">        <span class="comment"># inputs, labels = data</span></span><br><span class="line">        inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line"></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">            cate_i = labels[j].cpu().numpy()</span><br><span class="line">            pre_i = predicted[j].cpu().numpy()</span><br><span class="line">            conf_mat[cate_i, pre_i] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    acc_avg = conf_mat.trace() / conf_mat.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;test acc: &#123;:.2%&#125;&quot;</span>.<span class="built_in">format</span>(acc_avg))</span><br></pre></td></tr></table></figure><h2 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h2><table><thead><tr><th>状态</th><th>指标</th></tr></thead><tbody><tr><td>模型使用网络</td><td>Res-18</td></tr><tr><td>总Epoch</td><td>50</td></tr><tr><td>训练集acc</td><td>100%</td></tr><tr><td>验证集best acc</td><td>0.9731379731379731 in 30</td></tr><tr><td>测试集acc</td><td>97.19%</td></tr><tr><td>Train loss</td><td>0.0018</td></tr><tr><td>Valid loss</td><td>0.1196</td></tr></tbody></table><table><thead><tr><th>Acc曲线图</th><th>Loss曲线图</th></tr></thead><tbody><tr><td>![](&#x2F;Users&#x2F;kenton&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20220520165028148.png)</td><td>![](&#x2F;Users&#x2F;kenton&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20220520165037819.png)</td></tr></tbody></table><h2 id="Badcase分析"><a href="#Badcase分析" class="headerlink" title="Badcase分析"></a>Badcase分析</h2><p>限于篇幅移到了金山文档上「<a href="https://kdocs.cn/l/cpYKYpFmjKy1">点击链接</a>」🔗</p>]]></content>
      
      
      
        <tags>
            
            <tag> 花朵分类项目 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「花朵分类项目」（一）代码框架与Flower102数据集介绍</title>
      <link href="/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89%E4%BB%A3%E7%A0%81%E6%A1%86%E6%9E%B6%E4%B8%8EFlower102%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/"/>
      <url>/2022/05/19/%E3%80%8C%E8%8A%B1%E6%9C%B5%E5%88%86%E7%B1%BB%E9%A1%B9%E7%9B%AE%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89%E4%BB%A3%E7%A0%81%E6%A1%86%E6%9E%B6%E4%B8%8EFlower102%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="代码框架"><a href="#代码框架" class="headerlink" title="代码框架"></a>代码框架</h2><h3 id="模型训练代码框架"><a href="#模型训练代码框架" class="headerlink" title="模型训练代码框架"></a>模型训练代码框架</h3><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2ev6kbvcqj20jw0lb3zz.jpg" style="zoom: 50%;" /><h3 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h3><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2evasitcfj20vg0u0go9.jpg" style="zoom: 33%;" /><h3 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h3><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2evkpc7e0j219f0mf771.jpg" style="zoom: 33%;" /><h2 id="Flower102数据集"><a href="#Flower102数据集" class="headerlink" title="Flower102数据集"></a>Flower102数据集</h2><p>共有102类花朵，每个类别数量40到258不等 「**<a href="https://www.robots.ox.ac.uk/~vgg/data/flowers/102/">下载地址</a>**」</p><p>下载「<strong>Dataset图片</strong>」和「<strong>图像标签文件</strong>」</p><span id="more"></span><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2evvnzeogj20v00i0acs.jpg"></p><p>类别统计展示界面「**<a href="https://www.robots.ox.ac.uk/~vgg/data/flowers/102/categories.html">链接</a>**」</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2evsrbro2j20u00x378z.jpg"></p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2evssoatgj20u00wotd8.jpg"></p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2evstaypyj20u00w042o.jpg"></p><h2 id="相关代码书写"><a href="#相关代码书写" class="headerlink" title="相关代码书写"></a>相关代码书写</h2><h3 id="bins-x2F-split-flower-dataset-py-划分数据集"><a href="#bins-x2F-split-flower-dataset-py-划分数据集" class="headerlink" title="bins&#x2F;split_flower_dataset.py 划分数据集"></a>bins&#x2F;split_flower_dataset.py 划分数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :split_flower_dataset.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-3-30</span></span><br><span class="line"><span class="string"># @brief        :划分flower数据集</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_mkdir</span>(<span class="params">my_dir</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(my_dir):</span><br><span class="line">        os.makedirs(my_dir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">move_img</span>(<span class="params">imgs, root_dir, setname</span>):</span><br><span class="line">    data_dir = os.path.join(root_dir, setname)</span><br><span class="line">    my_mkdir(data_dir)</span><br><span class="line">    <span class="keyword">for</span> idx, path_imgs <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; / &#123;&#125;&quot;</span>.<span class="built_in">format</span>(idx, <span class="built_in">len</span>(imgs)))</span><br><span class="line">        shutil.copy(path_imgs, data_dir) <span class="comment"># 关键是这一行代码 移动图片到新文件夹</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; dataset, copy &#123;&#125; img to &#123;&#125;&quot;</span>.<span class="built_in">format</span>(setname, <span class="built_in">len</span>(imgs), data_dir))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 0. config</span></span><br><span class="line">    random_seed = <span class="number">20210309</span></span><br><span class="line">    train_ratio = <span class="number">0.8</span></span><br><span class="line">    valid_ratio = <span class="number">0.1</span></span><br><span class="line">    test_ratio = <span class="number">0.1</span></span><br><span class="line">    root_dir = <span class="string">r&#x27;/Users/kenton/Downloads/deeplearning_dataset/flower102&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. read list, shuffle</span></span><br><span class="line">    data_dir = os.path.join(root_dir, <span class="string">&quot;jpg&quot;</span>)</span><br><span class="line">    name_imgs = [p <span class="keyword">for</span> p <span class="keyword">in</span> os.listdir(data_dir) <span class="keyword">if</span> p.endswith(<span class="string">&quot;.jpg&quot;</span>)] <span class="comment"># 列表生成式</span></span><br><span class="line">    path_imgs = [os.path.join(data_dir, name) <span class="keyword">for</span> name <span class="keyword">in</span> name_imgs]</span><br><span class="line">    random.seed(random_seed)</span><br><span class="line">    random.shuffle(path_imgs)</span><br><span class="line">    <span class="built_in">print</span>(path_imgs[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. split</span></span><br><span class="line">    train_breakpoints = <span class="built_in">int</span>(<span class="built_in">len</span>(path_imgs) * train_ratio)</span><br><span class="line">    valid_breakpoints = <span class="built_in">int</span>(<span class="built_in">len</span>(path_imgs) * (train_ratio + valid_ratio))</span><br><span class="line">    test_breakpoints = <span class="built_in">int</span>(<span class="built_in">len</span>(path_imgs) * <span class="number">1</span>) <span class="comment"># 可以省略</span></span><br><span class="line"></span><br><span class="line">    train_img = path_imgs[: train_breakpoints]</span><br><span class="line">    valid_img = path_imgs[train_breakpoints: valid_breakpoints]</span><br><span class="line">    test_img = path_imgs[valid_breakpoints:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. copy and save</span></span><br><span class="line">    move_img(train_img, root_dir, <span class="string">&quot;train&quot;</span>)</span><br><span class="line">    move_img(valid_img, root_dir, <span class="string">&quot;valid&quot;</span>)</span><br><span class="line">    move_img(test_img, root_dir, <span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="datasets-x2F-flower102-py-读取数据集"><a href="#datasets-x2F-flower102-py-读取数据集" class="headerlink" title="datasets&#x2F;flower102.py 读取数据集"></a>datasets&#x2F;flower102.py 读取数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :flower102.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-3-30</span></span><br><span class="line"><span class="string"># @brief        :DataSets类 数据读取</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FlowerDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    cls_num = <span class="number">102</span> <span class="comment"># 类的一些属性</span></span><br><span class="line">    names = <span class="built_in">tuple</span>([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cls_num)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, transform=<span class="literal">None</span></span>): <span class="comment">#定义核心变量 比如路径 和 Transform预处理</span></span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.img_info = [] <span class="comment"># [(path, label),(),...]</span></span><br><span class="line">        self.label_array = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self._get_img_info()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        输入标量index，从硬盘中读取数据，并预处理 to tensor</span></span><br><span class="line"><span class="string">        :param index:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        path_img, label = self.img_info[index]</span><br><span class="line">        img = Image.<span class="built_in">open</span>(path_img).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        <span class="keyword">return</span> img, label, path_img</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.img_info) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;\ndata_dir:&#123;&#125; is a empty dir!&quot;</span>.<span class="built_in">format</span>(self.root_dir))</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_info)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_img_info</span>(<span class="params">self</span>): <span class="comment"># 读取数据的路径和标签 存在一个列表当中 给__getitem__使用</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        实现数据集的读取，将硬盘中的数据路径和标签 读取进来 存在一个list中</span></span><br><span class="line"><span class="string">        path, label</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        names_imgs = os.listdir(self.root_dir)</span><br><span class="line">        names_imgs = [n <span class="keyword">for</span> n <span class="keyword">in</span> names_imgs <span class="keyword">if</span> n.endswith(<span class="string">&#x27;.jpg&#x27;</span>)] <span class="comment"># pythonic 列表推导式</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读取mat形式label</span></span><br><span class="line">        label_file = <span class="string">&quot;imagelabels.mat&quot;</span></span><br><span class="line">        path_label_file = os.path.join(self.root_dir,<span class="string">&quot;..&quot;</span>,label_file)</span><br><span class="line">        <span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line">        label_array = loadmat(path_label_file)[<span class="string">&quot;labels&quot;</span>].squeeze()</span><br><span class="line">        self.label_array = label_array</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 匹配label</span></span><br><span class="line">        idx_imgs = [<span class="built_in">int</span>(n[<span class="number">6</span>:<span class="number">11</span>]) <span class="keyword">for</span> n <span class="keyword">in</span> names_imgs] <span class="comment"># 标号</span></span><br><span class="line">        path_imgs = [os.path.join(self.root_dir, n) <span class="keyword">for</span> n <span class="keyword">in</span> names_imgs] <span class="comment">#  路径 通过名称拼上根目录 列表推导式</span></span><br><span class="line">        self.img_info = [(p, <span class="built_in">int</span>(label_array[idx - <span class="number">1</span>] - <span class="number">1</span>)) <span class="keyword">for</span> p, idx <span class="keyword">in</span> <span class="built_in">zip</span>(path_imgs, idx_imgs)]</span><br><span class="line">        <span class="comment"># 获取整个图片的info 包含 path 和 label</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># test part</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    root_dir = <span class="string">r&#x27;/Users/kenton/Downloads/deeplearning_dataset/flower102/train&#x27;</span></span><br><span class="line">    test_dataset = FlowerDataset(root_dir)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(test_dataset))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">next</span>(<span class="built_in">iter</span>(test_dataset))) <span class="comment">#迭代器</span></span><br></pre></td></tr></table></figure><h3 id="scr-x2F-flower-train-py-训练代码"><a href="#scr-x2F-flower-train-py-训练代码" class="headerlink" title="scr&#x2F;flower_train.py 训练代码"></a>scr&#x2F;flower_train.py 训练代码</h3><p>argparse：接收命令行参数，应用场景：服务器训练时便于调参</p><p>训练信息保存：混淆矩阵可视化，loss曲线绘制便于观察模型训练趋势</p><p>path_errors记录：用于分析模型badcase</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :model_trainer.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-4-5</span></span><br><span class="line"><span class="string"># @brief        :训练代码</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> datasets.flower102 <span class="keyword">import</span> FlowerDataset</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">BASE_DIR = os.path.dirname(os.path.abspath(__file__)) <span class="comment"># 得到当前文件所在的目录</span></span><br><span class="line">sys.path.append(os.path.join(BASE_DIR, <span class="string">&quot;..&quot;</span>))</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"><span class="keyword">from</span> tools.model_trainer <span class="keyword">import</span> ModelTrainer</span><br><span class="line"><span class="keyword">from</span> tools.common_tools <span class="keyword">import</span> setup_seed, show_confMat, plot_line, Logger, check_data_dir, make_logger, get_model</span><br><span class="line"><span class="keyword">from</span> config.flower_config <span class="keyword">import</span> cfg</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> datasets.flower102 <span class="keyword">import</span> FlowerDataset</span><br><span class="line"><span class="keyword">from</span> tools.my_loss <span class="keyword">import</span> LabelSmoothLoss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">setup_seed(<span class="number">12345</span>) <span class="comment"># 先固定随机种子</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析命令行的参数</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Training&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>,default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&#x27;learning rate&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--bs&#x27;</span>,default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;training batch size&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--max_epoch&#x27;</span>,default=<span class="literal">None</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--data_root_dir&#x27;</span>,default=<span class="string">r&quot;/Users/kenton/Downloads/deeplearning_dataset/flower102&quot;</span>,</span><br><span class="line">                    <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;path to your dataset&#x27;</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接收参数</span></span><br><span class="line">cfg.lr_init = args.lr <span class="keyword">if</span> args.lr <span class="keyword">else</span> cfg.lr_init</span><br><span class="line">cfg.train_bs = args.bs <span class="keyword">if</span> args.bs <span class="keyword">else</span> cfg.train_bs</span><br><span class="line">cfg.max_epoch = args.max_epoch <span class="keyword">if</span> args.bs <span class="keyword">else</span> cfg.max_epoch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># step 0: config</span></span><br><span class="line">    <span class="comment"># 数据路径</span></span><br><span class="line">    train_dir = os.path.join(args.data_root_dir, <span class="string">&quot;train&quot;</span>)</span><br><span class="line">    valid_dir = os.path.join(args.data_root_dir, <span class="string">&quot;valid&quot;</span>)</span><br><span class="line">    path_state_dict = <span class="string">&quot;/Users/kenton/Downloads/deeplearning_dataset/pretrain_model/resnet18-f37072fd.pth&quot;</span> <span class="comment"># 预训练模型所在位置</span></span><br><span class="line">    check_data_dir(train_dir) <span class="comment"># 验证路径是否存在</span></span><br><span class="line">    check_data_dir(valid_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建logger</span></span><br><span class="line">    res_dir = os.path.join(BASE_DIR, <span class="string">&quot;..&quot;</span>, <span class="string">&quot;..&quot;</span>, <span class="string">&quot;results&quot;</span>)</span><br><span class="line">    logger, log_dir = make_logger(res_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># step 1: 数据集</span></span><br><span class="line">    <span class="comment"># 构建Dataset实例，构建DataLoader</span></span><br><span class="line">    train_data = FlowerDataset(root_dir=train_dir, transform=cfg.transforms_train)</span><br><span class="line">    valid_data = FlowerDataset(root_dir=valid_dir, transform=cfg.transforms_valid)</span><br><span class="line">    train_loader = DataLoader(dataset=train_data, batch_size=cfg.train_bs, shuffle=<span class="literal">True</span>, num_workers=cfg.workers)</span><br><span class="line">    valid_loader = DataLoader(dataset=valid_data, batch_size=cfg.valid_bs, num_workers=cfg.workers)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 模型</span></span><br><span class="line">    model = get_model(cfg, train_data.cls_num, logger)</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    # 加载预训练模型的参数 state_dict</span></span><br><span class="line"><span class="string">    if os.path.exists(path_state_dict):</span></span><br><span class="line"><span class="string">        pretrained_state_dict = torch.load(path_state_dict, map_location=&#x27;cpu&#x27;)</span></span><br><span class="line"><span class="string">        model.load_state_dict(pretrained_state_dict)</span></span><br><span class="line"><span class="string">        logger.info(&quot;Load pretrained model&quot;)</span></span><br><span class="line"><span class="string">    else:</span></span><br><span class="line"><span class="string">        logger.info(&quot;The pretrained model path &#123;&#125; is not exists&quot;.format(path_state_dict))</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    # 修改最后一层</span></span><br><span class="line"><span class="string">    num_ftrs = model.fc.in_features</span></span><br><span class="line"><span class="string">    model.fc = nn.Linear(num_ftrs, train_data.cls_num)</span></span><br><span class="line"><span class="string">    # to device</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 损失函数 优化器 等</span></span><br><span class="line">    <span class="keyword">if</span> cfg.lable_smooth:</span><br><span class="line">        loss_f = LabelSmoothLoss(cfg.label_smooth_eps)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loss_f = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=cfg.lr_init, momentum=cfg.momentum, weight_decay=cfg.weight_decay)</span><br><span class="line">    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, gamma=cfg.factor, milestones=cfg.milestones)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 迭代训练</span></span><br><span class="line">    loss_rec = &#123;<span class="string">&#x27;train&#x27;</span>:[], <span class="string">&quot;valid&quot;</span>:[]&#125;</span><br><span class="line">    acc_rec = &#123;<span class="string">&#x27;train&#x27;</span>:[], <span class="string">&quot;valid&quot;</span>:[]&#125;</span><br><span class="line">    best_acc, best_epoch = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(cfg.max_epoch):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># dataloader</span></span><br><span class="line">        loss_train, acc_train, mat_train, path_error_train = ModelTrainer.train(</span><br><span class="line">            train_loader, model, loss_f, optimizer, scheduler, epoch, device, cfg, logger)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># valid</span></span><br><span class="line">        loss_valid, acc_valid, mat_valid, path_error_valid = ModelTrainer.valid(</span><br><span class="line">            valid_loader, model, loss_f, device)</span><br><span class="line"></span><br><span class="line">        logger.info(<span class="string">&quot;Epoch[&#123;:0&gt;3&#125;/&#123;:0&gt;3&#125;] Train Acc:&#123;:.2%&#125; Valid Acc:&#123;:.2%&#125; Train loss:&#123;:.4f&#125; Valid loss:&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                cfg.max_epoch, acc_train, acc_valid, loss_train, loss_valid,</span><br><span class="line">                optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>]))</span><br><span class="line"></span><br><span class="line">        scheduler.step() <span class="comment"># 学习率进行更新！！！</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录训练信息</span></span><br><span class="line">        loss_rec[<span class="string">&quot;train&quot;</span>].append(loss_train), loss_rec[<span class="string">&quot;valid&quot;</span>].append(loss_valid)</span><br><span class="line">        acc_rec[<span class="string">&quot;train&quot;</span>].append(acc_train), acc_rec[<span class="string">&quot;valid&quot;</span>].append(acc_valid)</span><br><span class="line">        <span class="comment"># 保存混淆矩阵图</span></span><br><span class="line">        show_confMat(mat_train, train_data.names, <span class="string">&quot;train&quot;</span>, log_dir, epoch=epoch, verbose=epoch == cfg.max_epoch - <span class="number">1</span>)</span><br><span class="line">        show_confMat(mat_valid, valid_data.names, <span class="string">&quot;valid&quot;</span>, log_dir, epoch=epoch, verbose=epoch == cfg.max_epoch - <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 保存loss曲线 acc曲线</span></span><br><span class="line">        plt_x = np.arange(<span class="number">1</span>, epoch + <span class="number">2</span>)</span><br><span class="line">        plot_line(plt_x, loss_rec[<span class="string">&quot;train&quot;</span>], plt_x, loss_rec[<span class="string">&quot;valid&quot;</span>], mode=<span class="string">&quot;loss&quot;</span>, out_dir=log_dir)</span><br><span class="line">        plot_line(plt_x, acc_rec[<span class="string">&quot;train&quot;</span>], plt_x, acc_rec[<span class="string">&quot;valid&quot;</span>], mode=<span class="string">&quot;acc&quot;</span>, out_dir=log_dir)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        <span class="keyword">if</span> best_acc &lt; acc_valid <span class="keyword">or</span> epoch == cfg.max_epoch - <span class="number">1</span>:</span><br><span class="line">            best_epoch = epoch <span class="keyword">if</span> best_acc &lt; acc_valid <span class="keyword">else</span> best_epoch</span><br><span class="line">            best_acc = acc_valid <span class="keyword">if</span> best_acc &lt; acc_valid <span class="keyword">else</span> best_acc</span><br><span class="line">            checkpoint = &#123;<span class="string">&quot;model_state_dict&quot;</span>: model.state_dict(),</span><br><span class="line">                          <span class="string">&quot;optimizer_state_dict&quot;</span>: optimizer.state_dict(),</span><br><span class="line">                          <span class="string">&quot;epoch&quot;</span>: epoch,</span><br><span class="line">                          <span class="string">&quot;best_acc&quot;</span>: best_acc&#125;</span><br><span class="line">            pkl_name = <span class="string">&quot;checkpoint_&#123;&#125;.pkl&quot;</span>.<span class="built_in">format</span>(epoch) <span class="keyword">if</span> epoch == cfg.max_epoch - <span class="number">1</span> <span class="keyword">else</span> <span class="string">&quot;checkpoint_best.pkl&quot;</span></span><br><span class="line">            path_checkpoint = os.path.join(log_dir, pkl_name)</span><br><span class="line">            torch.save(checkpoint, path_checkpoint)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 保存错误图片的路径</span></span><br><span class="line">            err_ims_name = <span class="string">&quot;error_imgs_&#123;&#125;.pkl&quot;</span>.<span class="built_in">format</span>(epoch) <span class="keyword">if</span> epoch == cfg.max_epoch - <span class="number">1</span> <span class="keyword">else</span> <span class="string">&quot;error_imgs_best.pkl&quot;</span></span><br><span class="line">            path_err_img = os.path.join(log_dir, err_ims_name)</span><br><span class="line">            error_info = &#123;&#125;</span><br><span class="line">            error_info[<span class="string">&quot;train&quot;</span>] = path_error_train</span><br><span class="line">            error_info[<span class="string">&quot;valid&quot;</span>] = path_error_valid</span><br><span class="line">            pickle.dump(error_info, <span class="built_in">open</span>(path_err_img, <span class="string">&quot;wb&quot;</span>))</span><br><span class="line">    logger.info(<span class="string">&quot;&#123;&#125; done, best acc:&#123;&#125; in: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        datetime.strftime(datetime.now(), <span class="string">&quot;%m-%d_%H-%M&quot;</span>), best_acc, best_epoch))</span><br></pre></td></tr></table></figure><h3 id="tools-x2F-model-trainer-py-模型训练函数"><a href="#tools-x2F-model-trainer-py-模型训练函数" class="headerlink" title="tools&#x2F;model_trainer.py 模型训练函数"></a>tools&#x2F;model_trainer.py 模型训练函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># @file name    :model_trainer.py</span></span><br><span class="line"><span class="string"># @author       :zz0320</span></span><br><span class="line"><span class="string"># @data         :2022-3-31</span></span><br><span class="line"><span class="string"># @brief        :工具函数 用来模型训练 然后输出训练中的数据</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> tools.mixup <span class="keyword">import</span> mixup_data, mixup_criterion</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ModelTrainer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">data_loader, model, loss_f, optimizer, scheduler, epoch_idx, device, cfg, logger</span>):</span><br><span class="line">        model.train()</span><br><span class="line"></span><br><span class="line">        class_num = data_loader.dataset.cls_num</span><br><span class="line">        conf_mat = np.zeros((class_num, class_num))</span><br><span class="line">        loss_sigma = []</span><br><span class="line">        loss_mean = <span class="number">0</span></span><br><span class="line">        acc_avg = <span class="number">0</span></span><br><span class="line">        path_error = []</span><br><span class="line">        label_list = []</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># _, label = data</span></span><br><span class="line">            inputs, labels, path_imgs = data</span><br><span class="line">            label_list.extend(labels.tolist())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># inputs, labels = data</span></span><br><span class="line">            inputs, labels, path_imgs = data</span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># mixup</span></span><br><span class="line">            <span class="keyword">if</span> cfg.mixup:</span><br><span class="line">                mixup_inputs, label_a, label_b, lam = mixup_data(inputs, labels,</span><br><span class="line">                                        cfg.mixup_alpha,device)</span><br><span class="line">                inputs = mixup_inputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># forward &amp; backward</span></span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># loss计算</span></span><br><span class="line">            <span class="keyword">if</span> cfg.mixup:</span><br><span class="line">                loss = mixup_criterion(loss_f, outputs.cpu(), label_a.cpu(), label_b.cpu(), lam)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss = loss_f(outputs.cpu(), labels.cpu())</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 统计loss</span></span><br><span class="line">            loss_sigma.append(loss.item())</span><br><span class="line">            loss_mean = np.mean(loss_sigma)</span><br><span class="line"></span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">                cate_i = labels[j].cpu().numpy()</span><br><span class="line">                pre_i = predicted[j].cpu().numpy()</span><br><span class="line">                conf_mat[cate_i, pre_i] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> cate_i != pre_i:</span><br><span class="line">                    path_error.append((cate_i, pre_i, path_imgs[j]))</span><br><span class="line">            acc_avg = conf_mat.trace() / conf_mat.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 每 log_interval 个 iter 打印一次训练信息</span></span><br><span class="line">            <span class="keyword">if</span> i % cfg.log_interval == cfg.log_interval - <span class="number">1</span>:</span><br><span class="line">                logger.info(<span class="string">&quot;Training: Epoch[&#123;:0&gt;3&#125;/&#123;:0&gt;3&#125;] Iteration[&#123;:0&gt;3&#125;/&#123;:0&gt;3&#125;] Loss:&#123;:.4f&#125; Acc:&#123;:.2%&#125;&quot;</span>.<span class="built_in">format</span>(epoch_idx\</span><br><span class="line">                    + <span class="number">1</span>, cfg.max_epoch, i + <span class="number">1</span>, <span class="built_in">len</span>(data_loader), loss_mean, acc_avg))</span><br><span class="line">        logger.info(<span class="string">&quot;epoch:&#123;&#125; sampler:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch_idx, Counter(label_list)))</span><br><span class="line">        <span class="keyword">return</span> loss_mean, acc_avg, conf_mat, path_error</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">valid</span>(<span class="params">data_loader, model, loss_f, device</span>):</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">        class_num = data_loader.dataset.cls_num</span><br><span class="line">        conf_mat = np.zeros((class_num, class_num))</span><br><span class="line">        loss_sigma = []</span><br><span class="line">        path_error = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">            inputs, labels, path_imgs = data</span><br><span class="line">            <span class="comment"># inputs, labels = data</span></span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line"></span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = loss_f(outputs.cpu(), labels.cpu())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 统计混淆矩阵</span></span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">                cate_i = labels[j].cpu().numpy()</span><br><span class="line">                pre_i = predicted[j].cpu().numpy()</span><br><span class="line">                conf_mat[cate_i, pre_i] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> cate_i != pre_i:</span><br><span class="line">                    path_error.append((cate_i, pre_i, path_imgs[j]))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 统计loss</span></span><br><span class="line">            loss_sigma.append(loss.item())</span><br><span class="line"></span><br><span class="line">        acc_avg = conf_mat.trace() / conf_mat.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.mean(loss_sigma), acc_avg, conf_mat, path_error</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 花朵分类项目 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「环境配置」使用Conda配置mmdetction环境</title>
      <link href="/2022/05/19/%E3%80%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8Dmmdetection%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2022/05/19/%E3%80%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8Dmmdetection%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>参考文章「<a href="https://mmdetection.readthedocs.io/zh_CN/v2.22.0/get_started.html#id2"><strong>mmdet文档</strong></a>」「<a href="https://pytorch.org/get-started/locally/"><strong>Pytorch官网</strong></a>」</p><h2 id="Conda激活环境"><a href="#Conda激活环境" class="headerlink" title="Conda激活环境"></a>Conda激活环境</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n py39_torch112 python=3.9</span><br><span class="line">conda activate py39_torch112  </span><br></pre></td></tr></table></figure><h2 id="使用pip-下载Pytorch"><a href="#使用pip-下载Pytorch" class="headerlink" title="使用pip 下载Pytorch"></a>使用pip 下载Pytorch</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu</span><br><span class="line">pip3 install torch torchvision torchaudio</span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="安装mmcv-full-x3D-x3D-1-4-5"><a href="#安装mmcv-full-x3D-x3D-1-4-5" class="headerlink" title="安装mmcv-full &#x3D;&#x3D; 1.4.5"></a>安装mmcv-full &#x3D;&#x3D; 1.4.5</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mmcv-full==1.4.5</span><br></pre></td></tr></table></figure><h2 id="Conda-安装onnx和onnxruntime"><a href="#Conda-安装onnx和onnxruntime" class="headerlink" title="Conda 安装onnx和onnxruntime"></a>Conda 安装onnx和onnxruntime</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install onnx onnxruntime</span><br></pre></td></tr></table></figure><h2 id="安装依赖环境库"><a href="#安装依赖环境库" class="headerlink" title="安装依赖环境库"></a>安装依赖环境库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h2 id="之后-python-setup-py-develp"><a href="#之后-python-setup-py-develp" class="headerlink" title="之后 python setup.py develp"></a>之后 python setup.py develp</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py develop</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 环境配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「环境配置」（一）使用Conda配置mmdetction环境</title>
      <link href="/2022/05/19/%E3%80%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89mmdetection%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2022/05/19/%E3%80%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89mmdetection%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>参考文章「<a href="https://mmdetection.readthedocs.io/zh_CN/v2.22.0/get_started.html#id2"><strong>mmdet文档</strong></a>」「<a href="https://pytorch.org/get-started/locally/"><strong>Pytorch官网</strong></a>」</p><h2 id="Conda激活环境"><a href="#Conda激活环境" class="headerlink" title="Conda激活环境"></a>Conda激活环境</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n py39_torch112 python=3.9</span><br><span class="line">conda activate py39_torch112  </span><br></pre></td></tr></table></figure><h2 id="使用pip-下载Pytorch"><a href="#使用pip-下载Pytorch" class="headerlink" title="使用pip 下载Pytorch"></a>使用pip 下载Pytorch</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu</span><br><span class="line"></span><br><span class="line">pip3 install torch torchvision torchaudio</span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="安装mmcv-full-x3D-x3D-1-4-5"><a href="#安装mmcv-full-x3D-x3D-1-4-5" class="headerlink" title="安装mmcv-full &#x3D;&#x3D; 1.4.5"></a>安装mmcv-full &#x3D;&#x3D; 1.4.5</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mmcv-full==1.4.5</span><br></pre></td></tr></table></figure><h2 id="Conda-安装onnx和onnxruntime"><a href="#Conda-安装onnx和onnxruntime" class="headerlink" title="Conda 安装onnx和onnxruntime"></a>Conda 安装onnx和onnxruntime</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install onnx onnxruntime</span><br></pre></td></tr></table></figure><h2 id="安装依赖环境库"><a href="#安装依赖环境库" class="headerlink" title="安装依赖环境库"></a>安装依赖环境库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h2 id="之后-python-setup-py-develp"><a href="#之后-python-setup-py-develp" class="headerlink" title="之后 python setup.py develp"></a>之后 python setup.py develp</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py develop</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 环境配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「论文系列」（一）旷视科技CVPR2022【CREStereo】官方GitHub代码推理运行</title>
      <link href="/2022/05/11/%E3%80%8C%E8%AE%BA%E6%96%87%E7%B3%BB%E5%88%97%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80CVPR2022%E3%80%90CREStereo%E3%80%91%E5%AE%98%E6%96%B9GitHub%E4%BB%A3%E7%A0%81%E6%8E%A8%E7%90%86%E8%BF%90%E8%A1%8C/"/>
      <url>/2022/05/11/%E3%80%8C%E8%AE%BA%E6%96%87%E7%B3%BB%E5%88%97%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80CVPR2022%E3%80%90CREStereo%E3%80%91%E5%AE%98%E6%96%B9GitHub%E4%BB%A3%E7%A0%81%E6%8E%A8%E7%90%86%E8%BF%90%E8%A1%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="论文简介"><a href="#论文简介" class="headerlink" title="论文简介"></a>论文简介</h2><p>CVPR2022论文     <strong>《基于自适应相关级联递归网络的实用双目匹配》</strong>ttps:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.11483</p><p>原文链接：「<a href="https://arxiv.org/abs/2203.11483">Practical Stereo Matching via Cascaded Recurrent Network with Adaptive Correlation</a>」</p><p>作者解读视频：</p><iframe src="//player.bilibili.com/player.html?aid=383885340&bvid=BV1oZ4y1h7mL&cid=717464018&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><h2 id="运行准备"><a href="#运行准备" class="headerlink" title="运行准备"></a>运行准备</h2><p>在<strong>恒源云</strong>平台 配置一个<strong>CUDA10.1</strong>的环境 这里选择<strong>Tesla T4</strong> 「使用其他型号可能无法只能进行CUDA11及以上的配置」</p><span id="more"></span><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24u0rmh0gj20mt02tt8p.jpg" alt="image-20220511212511378"  /><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24u0x9dtgj20dg07t3yt.jpg" alt="image-20220511212457641"></p><p>设置成功后进入<strong>Jupyter-lab</strong>，安装<strong>OpenCV</strong></p><blockquote><p>参考「<a href="https://blog.csdn.net/keineahnung2345/article/details/84299532%E3%80%8D">https://blog.csdn.net/keineahnung2345/article/details/84299532」</a></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-python</span><br><span class="line">apt-get install -y libglib2.0-0</span><br><span class="line">apt-get install -y libsm6 libxext6</span><br><span class="line">apt-get install -y libxrender-dev</span><br></pre></td></tr></table></figure><p>之后根据官方GitHub「<a href="https://github.com/megvii-research/CREStereo%E3%80%8D">https://github.com/megvii-research/CREStereo」</a> 进行操作</p><blockquote><p>建议使用Download ZIP进行下载 之后放入服务器 unzip出来  git clone经常抽风卡在clone不动弹</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install -r requirements.txt</span><br></pre></td></tr></table></figure><blockquote><p>这里需要提前将requirements.txt 中的 MegEngine&gt;&#x3D;1.8.2 改为 MegEngine&#x3D;&#x3D;1.8.2 防止出现版本不兼容问题</p></blockquote><p>然后下载一个官方提供的预训练模型「<a href="https://drive.google.com/file/d/1Wx_-zDQh7BUFBmN9im_26DFpnf3AkXj4/view">Google网盘链接</a>」放到主目录下用于前向推理</p><p>最后运行如下代码，即可生成<strong>深度图</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py --model_path path_to_mge_model --left img/test/left.png --right img/test/right.png --size 1024x1536 --output disparity.png</span><br></pre></td></tr></table></figure><h2 id="运行结果展示"><a href="#运行结果展示" class="headerlink" title="运行结果展示"></a>运行结果展示</h2><p>最近正好在做双目视觉相关的工作，有一些双目的素材</p><p>实验了一下看看，效果还是挺不错的，下面放上几张效果图</p><p>如果后面能够利用声纳测距或者其他方法 做一个水下蝠鲼双目匹配的的真值数据集就更好</p><table><thead><tr><th align="center">左侧图</th><th align="center">右侧图</th><th align="center">深度图</th></tr></thead><tbody><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uqkkb4ej20zk0k0q53.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uqkkb4ej20zk0k0q53.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24ut82ysij20zk0k0t97.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24up9kgcej20zk0k0tak.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24upf2e6jj20zk0k0wgb.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uukp9oxj20zk0k0aav.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uww73g7j20zk0k0whd.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uww73g7j20zk0k0whd.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24ux180a4j20zk0k0q3s.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyh35k6j20zk0k0whf.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyeiq49j20zk0k0tbo.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyft7d6j20zk0k0jsd.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0hv9urj20zk0k0dip.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0hv9urj20zk0k0dip.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0ts6ulj20zk0k0gmk.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v658pitj20zk0k0mzc.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v64j9edj20zk0k0dhv.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v633e4hj20zk0k03z6.jpg"></td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> 论文系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「瞎折腾」支持Apple Silion的新版本Pytorch测试</title>
      <link href="/2022/05/10/%E3%80%8C%E7%9E%8E%E6%8A%98%E8%85%BE%E3%80%8D%E6%94%AF%E6%8C%81Apple%20Silion%E7%9A%84%E6%96%B0%E7%89%88%E6%9C%ACPytorch%E6%B5%8B%E8%AF%95/"/>
      <url>/2022/05/10/%E3%80%8C%E7%9E%8E%E6%8A%98%E8%85%BE%E3%80%8D%E6%94%AF%E6%8C%81Apple%20Silion%E7%9A%84%E6%96%B0%E7%89%88%E6%9C%ACPytorch%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>今天早晨起来看到了「机器之心」和「量子位」的公众号推文「<a href="https://mp.weixin.qq.com/s/UjnDVacH-6kSadPOnO32lQ">PyTorch宣布支持苹果M1芯片GPU加速：训练快6倍，推理提升21倍</a>」「<a href="https://mp.weixin.qq.com/s/TMreqcWsvu-EOB1qEgg6Kg">炼丹速度×7！你的Mac电脑也能在PyTorch训练中用GPU加速了</a>」</p><p>我的天 过年了过年了  <strong>Pytorch支持Apple Silion啦！！！</strong> </p><p>看了看推文 有Preview版本可以使用了 这还不折腾起来？ 开整！</p><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>先根据Pytorch的<a href="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/">官方指引</a>用Conda创建一个原生Python环境「M1系列Python3.9以上才是原生」</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n torch112_py39 python=3.9</span><br><span class="line">conda activate torch112_py39</span><br></pre></td></tr></table></figure><span id="more"></span><p>之后进入环境 安装torch</p><blockquote><p>这里需要注意 conda下面找不到torchaudio 需要在pip下面安装</p><p>安装结束后为了防止pip的环境与conda的环境冲突 删掉pip下面的torch</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision -c pytorch-nightly</span><br><span class="line">pip install torchaudio</span><br><span class="line">pip uninstall torch</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>再安装一个依赖库「可能有用😂」</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pkg-config libuv</span><br></pre></td></tr></table></figure><p>OK 环境配置好了 找个项目来试一试</p><h2 id="项目实测"><a href="#项目实测" class="headerlink" title="项目实测"></a>项目实测</h2><p>正好手头有目标检测CenterNet的项目代码 跑跑看看有没有提升</p><p>在Pycharm里面将编译环境改成设置好的<strong>torch112_py39</strong>环境</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dpqbqiihj20ya08uq3l.jpg"></p><p>之后安装项目依赖库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install matplotlib</span><br><span class="line">pip install torchsummary</span><br></pre></td></tr></table></figure><p>最后运行看看结果</p><table><thead><tr><th>Torch1.9.0｜Python3.8</th><th>Torch1.10.2 | Python3.9</th><th>Torch1.9.0</th><th>Python3.9</th></tr></thead><tbody><tr><td><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dqf6zkndj21fz0u078d.jpg"></td><td><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dqhrgzalj21fz0u0aeb.jpg"></td><td><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dvnjaakxj21fz0u078s.jpg"></td><td><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dqgzjxb4j21fz0u078n.jpg"></td></tr><tr><td>1.43FPS</td><td>2.42FPS</td><td>4.29FPS</td><td>5.85FPS</td></tr></tbody></table><blockquote><p>Torch针对MBP的GPU代码为‘mps’ 需要将model和data都移到device &#x3D; torch.device(‘mps’)上</p></blockquote><p>平台为MacBook M1 Pro 16+512 8核CPU 14核GPU</p><p>最后来看效果确实是有提升，考虑到目标检测过程中非torch操作很多且只能在CPU上跑这个项目，这种提升效果还是不错的，后续考虑再测试一下Train阶段的提升效果</p>]]></content>
      
      
      
        <tags>
            
            <tag> 尝鲜 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/05/08/hello-world/"/>
      <url>/2022/05/08/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><span id="more"></span><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
