<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>「环境配置」使用Conda配置mmdetction环境</title>
      <link href="/2022/05/19/%E3%80%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8Dmmdetection%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2022/05/19/%E3%80%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8Dmmdetection%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>参考文章「<a href="https://mmdetection.readthedocs.io/zh_CN/v2.22.0/get_started.html#id2"><strong>mmdet文档</strong></a>」「<a href="https://pytorch.org/get-started/locally/"><strong>Pytorch官网</strong></a>」</p><h2 id="Conda激活环境"><a href="#Conda激活环境" class="headerlink" title="Conda激活环境"></a>Conda激活环境</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n py39_torch112 python=3.9</span><br><span class="line">conda activate py39_torch112  </span><br></pre></td></tr></table></figure><h2 id="使用pip-下载Pytorch"><a href="#使用pip-下载Pytorch" class="headerlink" title="使用pip 下载Pytorch"></a>使用pip 下载Pytorch</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu</span><br><span class="line"></span><br><span class="line">pip3 install torch torchvision torchaudio</span><br></pre></td></tr></table></figure><span id="more"></span><h2 id="安装mmcv-full-x3D-x3D-1-4-5"><a href="#安装mmcv-full-x3D-x3D-1-4-5" class="headerlink" title="安装mmcv-full &#x3D;&#x3D; 1.4.5"></a>安装mmcv-full &#x3D;&#x3D; 1.4.5</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mmcv-full==1.4.5</span><br></pre></td></tr></table></figure><h2 id="Conda-安装onnx和onnxruntime"><a href="#Conda-安装onnx和onnxruntime" class="headerlink" title="Conda 安装onnx和onnxruntime"></a>Conda 安装onnx和onnxruntime</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install onnx onnxruntime</span><br></pre></td></tr></table></figure><h2 id="安装依赖环境库"><a href="#安装依赖环境库" class="headerlink" title="安装依赖环境库"></a>安装依赖环境库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h2 id="之后-python-setup-py-develp"><a href="#之后-python-setup-py-develp" class="headerlink" title="之后 python setup.py develp"></a>之后 python setup.py develp</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py develop</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 环境配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「论文系列」（一）旷视科技CVPR2022【CREStereo】官方GitHub代码推理运行</title>
      <link href="/2022/05/11/%E3%80%8C%E8%AE%BA%E6%96%87%E7%B3%BB%E5%88%97%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80CVPR2022%E3%80%90CREStereo%E3%80%91%E5%AE%98%E6%96%B9GitHub%E4%BB%A3%E7%A0%81%E6%8E%A8%E7%90%86%E8%BF%90%E8%A1%8C/"/>
      <url>/2022/05/11/%E3%80%8C%E8%AE%BA%E6%96%87%E7%B3%BB%E5%88%97%E3%80%8D%EF%BC%88%E4%B8%80%EF%BC%89%E6%97%B7%E8%A7%86%E7%A7%91%E6%8A%80CVPR2022%E3%80%90CREStereo%E3%80%91%E5%AE%98%E6%96%B9GitHub%E4%BB%A3%E7%A0%81%E6%8E%A8%E7%90%86%E8%BF%90%E8%A1%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="论文简介"><a href="#论文简介" class="headerlink" title="论文简介"></a>论文简介</h2><p>CVPR2022论文     <strong>《基于自适应相关级联递归网络的实用双目匹配》</strong>ttps:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.11483</p><p>原文链接：「<a href="https://arxiv.org/abs/2203.11483">Practical Stereo Matching via Cascaded Recurrent Network with Adaptive Correlation</a>」</p><p>作者解读视频：</p><iframe src="//player.bilibili.com/player.html?aid=383885340&bvid=BV1oZ4y1h7mL&cid=717464018&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><h2 id="运行准备"><a href="#运行准备" class="headerlink" title="运行准备"></a>运行准备</h2><p>在<strong>恒源云</strong>平台 配置一个<strong>CUDA10.1</strong>的环境 这里选择<strong>Tesla T4</strong> 「使用其他型号可能无法只能进行CUDA11及以上的配置」</p><span id="more"></span><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24u0rmh0gj20mt02tt8p.jpg" alt="image-20220511212511378"  /><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24u0x9dtgj20dg07t3yt.jpg" alt="image-20220511212457641"></p><p>设置成功后进入<strong>Jupyter-lab</strong>，安装<strong>OpenCV</strong></p><blockquote><p>参考「<a href="https://blog.csdn.net/keineahnung2345/article/details/84299532%E3%80%8D">https://blog.csdn.net/keineahnung2345/article/details/84299532」</a></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-python</span><br><span class="line">apt-get install -y libglib2.0-0</span><br><span class="line">apt-get install -y libsm6 libxext6</span><br><span class="line">apt-get install -y libxrender-dev</span><br></pre></td></tr></table></figure><p>之后根据官方GitHub「<a href="https://github.com/megvii-research/CREStereo%E3%80%8D">https://github.com/megvii-research/CREStereo」</a> 进行操作</p><blockquote><p>建议使用Download ZIP进行下载 之后放入服务器 unzip出来  git clone经常抽风卡在clone不动弹</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install -r requirements.txt</span><br></pre></td></tr></table></figure><blockquote><p>这里需要提前将requirements.txt 中的 MegEngine&gt;&#x3D;1.8.2 改为 MegEngine&#x3D;&#x3D;1.8.2 防止出现版本不兼容问题</p></blockquote><p>然后下载一个官方提供的预训练模型「<a href="https://drive.google.com/file/d/1Wx_-zDQh7BUFBmN9im_26DFpnf3AkXj4/view">Google网盘链接</a>」放到主目录下用于前向推理</p><p>最后运行如下代码，即可生成<strong>深度图</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py --model_path path_to_mge_model --left img/test/left.png --right img/test/right.png --size 1024x1536 --output disparity.png</span><br></pre></td></tr></table></figure><h2 id="运行结果展示"><a href="#运行结果展示" class="headerlink" title="运行结果展示"></a>运行结果展示</h2><p>最近正好在做双目视觉相关的工作，有一些双目的素材</p><p>实验了一下看看，效果还是挺不错的，下面放上几张效果图</p><p>如果后面能够利用声纳测距或者其他方法 做一个水下蝠鲼双目匹配的的真值数据集就更好</p><table><thead><tr><th align="center">左侧图</th><th align="center">右侧图</th><th align="center">深度图</th></tr></thead><tbody><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uqkkb4ej20zk0k0q53.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uqkkb4ej20zk0k0q53.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24ut82ysij20zk0k0t97.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24up9kgcej20zk0k0tak.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24upf2e6jj20zk0k0wgb.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uukp9oxj20zk0k0aav.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uww73g7j20zk0k0whd.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uww73g7j20zk0k0whd.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24ux180a4j20zk0k0q3s.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyh35k6j20zk0k0whf.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyeiq49j20zk0k0tbo.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyft7d6j20zk0k0jsd.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0hv9urj20zk0k0dip.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0hv9urj20zk0k0dip.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0ts6ulj20zk0k0gmk.jpg"></td></tr><tr><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v658pitj20zk0k0mzc.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v64j9edj20zk0k0dhv.jpg"></td><td align="center"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h24v633e4hj20zk0k03z6.jpg"></td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> 论文系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>「瞎折腾」支持Apple Silion的新版本Pytorch测试</title>
      <link href="/2022/05/10/%E3%80%8C%E7%9E%8E%E6%8A%98%E8%85%BE%E3%80%8D%E6%94%AF%E6%8C%81Apple%20Silion%E7%9A%84%E6%96%B0%E7%89%88%E6%9C%ACPytorch%E6%B5%8B%E8%AF%95/"/>
      <url>/2022/05/10/%E3%80%8C%E7%9E%8E%E6%8A%98%E8%85%BE%E3%80%8D%E6%94%AF%E6%8C%81Apple%20Silion%E7%9A%84%E6%96%B0%E7%89%88%E6%9C%ACPytorch%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>今天早晨起来看到了「机器之心」和「量子位」的公众号推文「<a href="https://mp.weixin.qq.com/s/UjnDVacH-6kSadPOnO32lQ">PyTorch宣布支持苹果M1芯片GPU加速：训练快6倍，推理提升21倍</a>」「<a href="https://mp.weixin.qq.com/s/TMreqcWsvu-EOB1qEgg6Kg">炼丹速度×7！你的Mac电脑也能在PyTorch训练中用GPU加速了</a>」</p><p>我的天 过年了过年了  <strong>Pytorch支持Apple Silion啦！！！</strong> </p><p>看了看推文 有Preview版本可以使用了 这还不折腾起来？ 开整！</p><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>先根据Pytorch的<a href="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/">官方指引</a>用Conda创建一个原生Python环境「M1系列Python3.9以上才是原生」</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n torch112_py39 python=3.9</span><br><span class="line">conda activate torch112_py39</span><br></pre></td></tr></table></figure><span id="more"></span><p>之后进入环境 安装torch</p><blockquote><p>这里需要注意 conda下面找不到torchaudio 需要在pip下面安装</p><p>安装结束后为了防止pip的环境与conda的环境冲突 删掉pip下面的torch</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision -c pytorch-nightly</span><br><span class="line">pip install torchaudio</span><br><span class="line">pip uninstall torch</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>再安装一个依赖库「可能有用😂」</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pkg-config libuv</span><br></pre></td></tr></table></figure><p>OK 环境配置好了 找个项目来试一试</p><h2 id="项目实测"><a href="#项目实测" class="headerlink" title="项目实测"></a>项目实测</h2><p>正好手头有目标检测CenterNet的项目代码 跑跑看看有没有提升</p><p>在Pycharm里面将编译环境改成设置好的<strong>torch112_py39</strong>环境</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dpqbqiihj20ya08uq3l.jpg"></p><p>之后安装项目依赖库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install matplotlib</span><br><span class="line">pip install torchsummary</span><br></pre></td></tr></table></figure><p>最后运行看看结果</p><table><thead><tr><th>Torch1.9.0｜Python3.8</th><th>Torch1.10.2 | Python3.9</th><th>Torch1.9.0</th><th>Python3.9</th></tr></thead><tbody><tr><td><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dqf6zkndj21fz0u078d.jpg"></td><td><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dqhrgzalj21fz0u0aeb.jpg"></td><td><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dvnjaakxj21fz0u078s.jpg"></td><td><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h2dqgzjxb4j21fz0u078n.jpg"></td></tr><tr><td>1.43FPS</td><td>2.42FPS</td><td>4.29FPS</td><td>5.85FPS</td></tr></tbody></table><blockquote><p>Torch针对MBP的GPU代码为‘mps’ 需要将model和data都移到device &#x3D; torch.device(‘mps’)上</p></blockquote><p>平台为MacBook M1 Pro 16+512 8核CPU 14核GPU</p><p>最后来看效果确实是有提升，考虑到目标检测过程中非torch操作很多且只能在CPU上跑这个项目，这种提升效果还是不错的，后续考虑再测试一下Train阶段的提升效果</p>]]></content>
      
      
      
        <tags>
            
            <tag> 尝鲜 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/05/08/hello-world/"/>
      <url>/2022/05/08/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><span id="more"></span><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
