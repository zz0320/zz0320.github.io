[{"title":"「论文系列」（一）旷视科技CVPR2022 CREStereo 官方GitHub代码推理运行","url":"/2022/05/11/「论文系列」（一）旷视科技CVPR2022 CREStereo 官方GitHub代码推理运行/","content":"\n## 论文简介：\n\nCVPR2022论文     **《基于自适应相关级联递归网络的实用双目匹配》**\n\n原文链接：「[Practical Stereo Matching via Cascaded Recurrent Network with Adaptive Correlation](https://arxiv.org/abs/2203.11483)」\n\n作者解读视频：\n\n<iframe src=\"//player.bilibili.com/player.html?aid=383885340&bvid=BV1oZ4y1h7mL&cid=717464018&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n## 运行准备：\n\n在**恒源云**平台 配置一个**CUDA10.1**的环境 这里选择**Tesla T4** 「使用其他型号可能无法只能进行CUDA11及以上的配置」\n\n<!-- more -->\n\n<img src=\"https://tva1.sinaimg.cn/large/e6c9d24ely1h24u0rmh0gj20mt02tt8p.jpg\" alt=\"image-20220511212511378\"  />\n\n![image-20220511212457641](https://tva1.sinaimg.cn/large/e6c9d24ely1h24u0x9dtgj20dg07t3yt.jpg)\n\n设置成功后进入**Jupyter-lab**，安装**OpenCV**\n\n> 参考「https://blog.csdn.net/keineahnung2345/article/details/84299532」\n\n```\npip install opencv-python\napt-get install -y libglib2.0-0\napt-get install -y libsm6 libxext6\napt-get install -y libxrender-dev\n```\n\n之后根据官方GitHub「https://github.com/megvii-research/CREStereo」 进行操作\n\n> 建议使用Download ZIP进行下载 之后放入服务器 unzip出来  git clone经常抽风卡在clone不动弹\n\n```\npython3 -m pip install -r requirements.txt\n```\n\n> 这里需要提前将requirements.txt 中的 MegEngine>=1.8.2 改为 MegEngine==1.8.2 防止出现版本不兼容问题\n\n然后下载一个官方提供的预训练模型「[Google网盘链接](https://drive.google.com/file/d/1Wx_-zDQh7BUFBmN9im_26DFpnf3AkXj4/view)」放到主目录下用于前向推理\n\n最后运行如下代码，即可生成**深度图**\n\n```\npython3 test.py --model_path path_to_mge_model --left img/test/left.png --right img/test/right.png --size 1024x1536 --output disparity.png\n```\n\n## 运行结果展示\n\n最近正好在做双目视觉相关的工作，有一些双目的素材\n\n实验了一下看看，效果还是挺不错的，下面放上几张效果图\n\n如果后面能够利用声纳测距或者其他方法 做一个水下蝠鲼双目匹配的的真值数据集就更好\n\n|                            左侧图                            |                            右侧图                            |                            深度图                            |\n| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |\n| ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24uqkkb4ej20zk0k0q53.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24uqkkb4ej20zk0k0q53.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24ut82ysij20zk0k0t97.jpg) |\n| ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24up9kgcej20zk0k0tak.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24upf2e6jj20zk0k0wgb.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24uukp9oxj20zk0k0aav.jpg) |\n| ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24uww73g7j20zk0k0whd.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24uww73g7j20zk0k0whd.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24ux180a4j20zk0k0q3s.jpg) |\n| ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyh35k6j20zk0k0whf.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyeiq49j20zk0k0tbo.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24uyft7d6j20zk0k0jsd.jpg) |\n| ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0hv9urj20zk0k0dip.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0hv9urj20zk0k0dip.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24v0ts6ulj20zk0k0gmk.jpg) |\n| ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24v658pitj20zk0k0mzc.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24v64j9edj20zk0k0dhv.jpg) | ![](https://tva1.sinaimg.cn/large/e6c9d24ely1h24v633e4hj20zk0k03z6.jpg) |\n\n","tags":["论文系列"]},{"title":"「蝠鲼项目」（一）水下仿生蝠鲼数据集获取及VOC格式转化为COCO格式","url":"/2022/05/10/「蝠鲼项目」（一）水下仿生蝠鲼数据集获取及VOC格式转化为COCO格式/","content":"\n## 拍摄流程：\n\n使用手机相机📱、水密相机📷「后面进水了😭」还有固定在水池玻璃围栏上的水密监控📹进行录像\n\n蝠鲼团队的同学帮忙操纵蝠鲼进行各种姿态的运动，保证蝠鲼的各个角度都被捕捉到\n\n后期经过粗略的剪辑「有蝠鲼的留下，没有蝠鲼的删掉」得到原始视频\n\n> 这里出现了“一号坑”：水密监控是网络传输格式，需要特殊的上位机进行录像，后期也需要单独下载VLC软件进行视频格式转换，直接双击源文件是播放不了的\n\n## 视频切分为图片：\n\n有了原始视频就要进行切分得到图片，这里用调用OpenCV的“轮子”进行切分，切分标准为每10帧切1张\n\n下面贴上代码：\n\n<!-- more -->\n```python\n# -*- coding:UTF-8 -*-\n\"\"\"\n# @file name  : video2image.py\n# @author     : zz0320\n# @brief      : 将视频切分为图片\n\"\"\"\n\nimport cv2\n\n# 定义保存图片函数\n# image:要保存的图片名字\n# addr；图片地址与相片名字的前部分\n# num: 相片，名字的后缀。int 类型\ndef save_image(image, addr, num):\n    address = addr + str(num) + '.jpg'\n    cv2.imwrite(address, image)\n\n\n# 读取视频文件\n\nj = 0\nvideo_name = \"IMG_8777.mp4\"  # 视频名称\nvideo_dir = \"/Users/kenton/Downloads/集群重点研发/蝠鲼数据集/video/\"  # 视频根目录\nvideoCapture = cv2.VideoCapture(video_dir + video_name)\n\n# videoCapture=cv2.VideoCapture(1) # 这里就是直接调用摄像头\n\n# 读帧\nsuccess, frame = videoCapture.read()\n\ntimeF = 10  # 按需更改\ni = 0\nwhile success:\n    i = i + 1\n    if (i % timeF == 0):\n        s = 10000\n        j = j + 1\n        s += j\n        save_image(frame, '/Users/kenton/Downloads/集群重点研发/蝠鲼数据集/video/test/{}'.format(video_name[:-4]), s)\n        # {}前的部分为保存视频的地址\n        print('save image:', i)\n    success, frame = videoCapture.read()\n```\n\n## 标签设定与标签标定：\n\n切分完以后就得到**一堆一堆的图片**「八千多张」\n\n然后找师姐和师弟帮忙一起打标签「非常感谢🙏」\n\n打标签是在「https://www.makesense.ai/」这个网站上打的\n\n输出格式可以选择为**VOC**、**YOLO**或者直接**XML**\n\n**标签**按照相机相对于蝠鲼的位置一共设定了**8个类**，分别为「**left_front**，**left_rear**，**right_front**，**right_rear**，**front**，**rear**，**left**，**right**」\n\n> 这里是“二号坑”：最早的时候打的标签是中文，但是后面推理的时候无法正确在图片上输出中文，所以在后面进行标签转化的时候需要进行英文替换，而且这八个类的顺序也十分十分十分重要，会影响到后面loss的计算。\n\n下面是打标网站的界面和打标的部分实况截图\n\n<img src=\"https://wx2.sinaimg.cn/large/005XjMv9ly1h23cjwewxsj30xi0rajyn.jpg\" width=80% height=50% align=center referrerpolicy=\"no-referrer\"/>\n\n<img src=\"https://wx4.sinaimg.cn/large/005XjMv9ly1h23cjvruujj30xu0iwn3c.jpg\" width=80% height=50% align=center referrerpolicy=\"no-referrer\"/>\n\n## 文件过滤\n\n因为打标签的时候是图片文件-标签文件一一对应的，如果打标过程中遇到一些质量较低的图片就会选择跳过不打标签\n\n这就造成了有部分图片并没有标签，我们需要去掉这些无标签的图片，这里用标签文件名「不含.xml」进行匹配过滤这些「无用」图片\n\n程序如下：\n\n```python\n# -*- coding:UTF-8 -*-\n\"\"\"\n# @file name  : remove_useless_image.py\n# @author     : zz0320\n# @brief      : 删除没有标签的照片\n\"\"\"\n\nimport os\n\npath1 = r\"/Users/kenton/Downloads/集群重点研发/蝠鲼数据集/jpg/处理结果集合/数据对齐与分割程序/VOCdevkit/VOC2007/Annotations\"       #对比的文件夹（标签文件夹）\npath2 = r\"/Users/kenton/Downloads/集群重点研发/蝠鲼数据集/jpg/处理结果集合/数据对齐与分割程序/VOCdevkit/VOC2007/JPEGImages\"        #删除文件的文件夹（图片文件夹）\nfilelist1 = os.listdir(path1) #该文件夹下所有的文件（包括文件夹）\nfilelist2 = os.listdir(path2)\ntp = \".xml\"      #要匹配标签文件的后缀\n\n\nfor file2 in filelist2:\n    filename = os.path.splitext(file2)[0] + tp  # 匹配文件名\n    if filename not in filelist1:           #如果没有对应匹配文件，就删除\n        os.remove(os.path.join(path2, file2))\n\n```\n\n\n\n## VOC标签格式：\n\n网站打标签后输出的文件格式没有COCO格式可以选择，所以在这里选择VOC数据集，方便后期的转换\n\n这里介绍一下VOC标签的存放格式和内部格式\n\n存放格式如下：「只考虑目标检测任务」\n\n```\n#第一级\nVOCdevkit\n├── VOC2007\n└── VOC2012\n#第二级\nVOCdevkit/VOC2007\n├── Annotations\n├── ImageSets\n├── JPEGImages\n\nVOCdevkit/VOC2012\n├── Annotations\n├── ImageSets\n├── JPEGImages\n\n#以VOC2007为例，第三级\n## Annotations\nVOCdevkit/VOC2007/Annotations/\n├── 000001.xml\n...\n## JPEGImages\nVOCdevkit/VOC2007/JPEGImages/\n├── 000001.jpg\n...\n\n```\n\n内部格式如下：\n\n```xml\n<annotation>\n\t<folder>油罐车图片</folder>\n\t<filename>1.jpg</filename>\n\t<path>D:\\Desktop\\油罐车图片\\1.jpg</path>\n\t<source>\n\t\t<database>Unknown</database>\n\t</source>\n\t<size>\n\t\t<width>312</width>\n\t\t<height>208</height>\n\t\t<depth>3</depth>\n\t</size>\n\t<segmented>0</segmented>\n\t<object>\n\t\t<name>redCap</name>\n\t\t<pose>Unspecified</pose>\n\t\t<truncated>0</truncated>\n\t\t<difficult>0</difficult>\n\t\t<bndbox>\n\t\t\t<xmin>43</xmin>\n\t\t\t<ymin>92</ymin>\n\t\t\t<xmax>96</xmax>\n\t\t\t<ymax>144</ymax>\n\t\t</bndbox>\n\t</object>\n\t<object>\n\t\t<name>yellowCap</name>\n\t\t<pose>Unspecified</pose>\n\t\t<truncated>0</truncated>\n\t\t<difficult>0</difficult>\n\t\t<bndbox>\n\t\t\t<xmin>147</xmin>\n\t\t\t<ymin>98</ymin>\n\t\t\t<xmax>198</xmax>\n\t\t\t<ymax>151</ymax>\n\t\t</bndbox>\n\t</object>\n\t<object>\n\t\t<name>oilTruck</name>\n\t\t<pose>Unspecified</pose>\n\t\t<truncated>0</truncated>\n\t\t<difficult>0</difficult>\n\t\t<bndbox>\n\t\t\t<xmin>111</xmin>\n\t\t\t<ymin>46</ymin>\n\t\t\t<xmax>266</xmax>\n\t\t\t<ymax>157</ymax>\n\t\t</bndbox>\n\t</object>\n</annotation>\n```\n\n这里如果需要进行标签转换的话，可以使用如下代码进行替换：\n\n```python\n# -*- coding:UTF-8 -*-\n\"\"\"\n# @file name  : chang_xml_label.py\n# @author     : zz0320\n# @brief      : 批量修改xml文件中的类别名称 当有多个物体时，多个物体的名称均能被修改\n\"\"\"\n\nfrom lxml.etree import Element, SubElement, tostring, ElementTree\nfrom xml.dom import minidom\nimport xml.etree.ElementTree as ET\nfrom xml.etree import ElementTree as etree\nimport os\nimport re\nfrom lxml import etree\n# 修改自己的路径\n# parser = ET.XMLParser(encoding=\"utf-8\")\ntemplate_file = r'/Users/kenton/Downloads/集群重点研发/蝠鲼数据集/jpg/处理结果集合/VOCdevkit/VOC2007/Annotations/'  #这里是存放xml文件的文件夹\nxmllist = os.listdir(template_file)\n# text = re.sub(u\"[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f]+\", u\"\", text)\nfor xml in xmllist:\n    if xml == '.DS_Store':\n        continue\n    # print(xml)\n    file = open(os.path.join(template_file, xml)).read()\n    # print(type(file))\n    file = file.replace(\"&amp;\", \"_\")\n    file = file.replace(\"&\", \"_\")\n    # print(file)\n    tree = ET.ElementTree(ET.fromstring(file))\n    root = tree.getroot() # 获取根节点\n    for child in root:\n\n        print(child.tag,child.attrib)\n        if child.tag == 'object':\n            name=child.find('name').text\n            # print(name)\n            if name == '左前':\n                child.find('name').text='left_front'\n                tree=ET.ElementTree(root)\n            elif name == '左后':\n                child.find('name').text = 'left_rear'\n                tree = ET.ElementTree(root)\n            elif name == '右前':\n                child.find('name').text = 'right_front'\n                tree = ET.ElementTree(root)\n            elif name == '右后':\n                child.find('name').text = 'right_rear'\n                tree = ET.ElementTree(root)\n            elif name == '前侧':\n                child.find('name').text = 'front'\n                tree = ET.ElementTree(root)\n            elif name == '后侧':\n                child.find('name').text = 'rear'\n                tree = ET.ElementTree(root)\n            elif name == '左侧':\n                child.find('name').text = 'left'\n                tree = ET.ElementTree(root)\n            elif name == '右侧':\n                child.find('name').text = 'right'\n                tree = ET.ElementTree(root)\n    # print(tree)\n    tree.write(os.path.join(template_file, xml))\n```\n\n> 这里有个“三号坑”：每次系统运行的时候都会出现\".DS_Store\"或者jupyter下面的时候出现\".jupyter xxxx\"的类似文件，如果程序报错可以考虑忽略这种文件\n\n这里还可以延伸出一个计数程序，可以用于判定程序中各类的类别数量，如下：\n\n```python\n# -*- coding:UTF-8 -*-\n\"\"\"\n# @file name  : count.py\n# @author     : zz0320\n# @brief      : 各类数量统计\n\"\"\"\n\nimport xml.etree.ElementTree as ET\nimport os\n# 修改自己的路径\ncount0 = count1 = count2 = count3 = count4 = count5 = count6 = count7 = 0\ntemplate_file = r'/Users/kenton/Downloads/集群重点研发/蝠鲼数据集/jpg/处理结果集合/VOCdevkit/VOC2007/Annotations'  #这里是存放xml文件的文件夹\nxmllist = os.listdir(template_file)\nfor xml in xmllist:\n    if xml == '.DS_Store':\n        continue\n    # print(xml)\n\n    # tree = ET.parse(os.path.join(template_file,xml))\n    # root = tree.getroot() # 获取根节点\n\n    # print(xml)\n    file = open(os.path.join(template_file, xml)).read()\n    # print(type(file))\n    file = file.replace(\"&amp;\", \"_\")\n    file = file.replace(\"&\", \"_\")\n    # print(file)\n    tree = ET.ElementTree(ET.fromstring(file))\n    root = tree.getroot() # 获取根节点\n    for child in root:\n        # print(child.tag,child.attrib)\n        if child.tag == 'object':\n            name=child.find('name').text\n            # print(name)\n            if name == 'left_front':\n                count0 += 1\n            elif name == 'left_rear':\n                count1 += 1\n\n            elif name == 'right_front':\n                count2 += 1\n\n            elif name == 'right_rear':\n                count3 += 1\n\n            elif name == 'front':\n                count4 += 1\n\n            elif name == 'rear':\n                count5 += 1\n\n            elif name == 'left':\n                count6 += 1\n\n            elif name == 'right':\n                count7 += 1\n\nprint(count0,count1,count2,count3,count4,count5,count6,count7)\n```\n\n## COCO数据格式\n\ncoco数据集的格式实在是有些繁琐，限于篇幅 这里贴一个链接，感兴趣的可以自行查看\n\n> https://zhuanlan.zhihu.com/p/29393415\n\n## 转化成COCO格式：\n\n下面就是voc格式转成coco的程序 顺带可以进行数据集的随机划分 划分为「训练集train」「验证集val」「测试集test」\n\n运行后可以直接生成coco的文件分布和json文件\n\n> 这里还有一个“四号坑”：代码中段def convert函数下面有一个StartIndex这个是生成的json文件中图片类别的起始计数数值，这里一定要改成一个天马行空的数字，我这里是设定的21800，因为不这么设定会和后面标签的计数冲突「都是起始0」，导致训练时部分loss始终为0\n\n```python\n# -*- coding:UTF-8 -*-\n\"\"\"\n# @file name  : voc2coco.py\n# @author     : zz0320\n# @brief      : voc格式转成coco & 数据集划分\n\"\"\"\nimport os\nimport random\nimport shutil\nimport sys\nimport json\nimport glob\nimport xml.etree.ElementTree as ET\n\n\n\"\"\"\nYou only need to set the following three parts\n1.val_files_num : num of validation samples from your all samples\n2.test_files_num = num of test samples from your all samples\n3.voc_annotations : path to your VOC dataset Annotations\n \n\"\"\"\nval_files_num = 500\ntest_files_num = 200\nvoc_annotations = '/Users/kenton/Downloads/集群重点研发/蝠鲼数据集/jpg/处理结果集合/VOCdevkit/VOC2007/Annotations/'\n#voc数据集annotations的地址\n\nsplit = voc_annotations.split('/')\ncoco_name = split[-3]\ndel split[-3]\ndel split[-2]\ndel split[-1]\ndel split[0]\n# print(split)\nmain_path = ''\nfor i in split:\n    main_path += '/' + i\n\nmain_path = main_path + '/'\n\n# print(main_path)\n\ncoco_path = os.path.join(main_path, coco_name+'_COCO/')\ncoco_images = os.path.join(main_path, coco_name+'_COCO/images')\ncoco_json_annotations = os.path.join(main_path, coco_name+'_COCO/annotations/')\nxml_val = os.path.join(main_path, 'xml', 'xml_val/')\nxml_test = os.path.join(main_path, 'xml/', 'xml_test/')\nxml_train = os.path.join(main_path, 'xml/', 'xml_train/')\n\nvoc_images = os.path.join(main_path, coco_name, 'JPEGImages/')\n\ndef mkdir(path):\n    path=path.strip()\n    path=path.rstrip(\"\\\\\")\n    isExists=os.path.exists(path)\n    if not isExists:\n        os.makedirs(path)\n        print(path+' ----- folder created')\n        return True\n    else:\n        print(path+' ----- folder existed')\n        return False\nmkdir(coco_path)\nmkdir(coco_images)\nmkdir(coco_json_annotations)\nmkdir(xml_val)\nmkdir(xml_test)\nmkdir(xml_train)\n\n#voc images copy to coco images\nfor i in os.listdir(voc_images):\n    img_path = os.path.join(voc_images + i)\n    shutil.copy(img_path, coco_images)\n    # voc images copy to coco images\nfor i in os.listdir(voc_annotations):\n    img_path = os.path.join(voc_annotations + i)\n    shutil.copy(img_path, xml_train)\n\nprint(\"\\n\\n %s files copied to %s\" % (val_files_num, xml_val))\n\nfor i in range(val_files_num):\n    if len(os.listdir(xml_train)) > 0:\n\n        random_file = random.choice(os.listdir(xml_train))\n        #         print(\"%d) %s\"%(i+1,random_file))\n        source_file = \"%s/%s\" % (xml_train, random_file)\n\n        if random_file not in os.listdir(xml_val):\n            shutil.move(source_file, xml_val)\n        else:\n            random_file = random.choice(os.listdir(xml_train))\n            source_file = \"%s/%s\" % (xml_train, random_file)\n            shutil.move(source_file, xml_val)\n    else:\n        print('The folders are empty, please make sure there are enough %d file to move' % (val_files_num))\n        break\n\nfor i in range(test_files_num):\n    if len(os.listdir(xml_train)) > 0:\n\n        random_file = random.choice(os.listdir(xml_train))\n        #         print(\"%d) %s\"%(i+1,random_file))\n        source_file = \"%s/%s\" % (xml_train, random_file)\n\n        if random_file not in os.listdir(xml_test):\n            shutil.move(source_file, xml_test)\n        else:\n            random_file = random.choice(os.listdir(xml_train))\n            source_file = \"%s/%s\" % (xml_train, random_file)\n            shutil.move(source_file, xml_test)\n    else:\n        print('The folders are empty, please make sure there are enough %d file to move' % (val_files_num))\n        break\n\nprint(\"\\n\\n\" + \"*\" * 27 + \"[ Done ! Go check your file ]\" + \"*\" * 28)\n\n# !/usr/bin/python\n\n# pip install lxml\n\n\nSTART_BOUNDING_BOX_ID = 1\n# PRE_DEFINE_CATEGORIES = None\n\n\n# If necessary, pre-define category and its id\nPRE_DEFINE_CATEGORIES = {\"left_front\": 0, \"left_rear\": 1, \"right_front\": 2, \"right_rear\": 3,\n    \"front\": 4, \"rear\": 5, \"left\": 6, \"right\": 7}\n\n\"\"\"\nmain code below are from\nhttps://github.com/Tony607/voc2coco\n\"\"\"\n\n\ndef get(root, name):\n    vars = root.findall(name)\n    return vars\n\n\ndef get_and_check(root, name, length):\n    vars = root.findall(name)\n    if len(vars) == 0:\n        raise ValueError(\"Can not find %s in %s.\" % (name, root.tag))\n    if length > 0 and len(vars) != length:\n        raise ValueError(\n            \"The size of %s is supposed to be %d, but is %d.\"\n            % (name, length, len(vars))\n        )\n    if length == 1:\n        vars = vars[0]\n    return vars\n\n\ndef get_filename_as_int(filename):\n    try:\n        filename = filename.replace(\"\\\\\", \"/\")\n        filename = os.path.splitext(os.path.basename(filename))[0]\n        return int(filename)\n    except:\n        raise ValueError(\"Filename %s is supposed to be an integer.\" % (filename))\n\n\ndef get_categories(xml_files):\n    \"\"\"Generate category name to id mapping from a list of xml files.\n\n    Arguments:\n        xml_files {list} -- A list of xml file paths.\n\n    Returns:\n        dict -- category name to id mapping.\n    \"\"\"\n    classes_names = []\n    for xml_file in xml_files:\n        file = open(xml_file).read()\n        file = file.replace(\"&amp;\", \"_\")\n        file = file.replace(\"&\", \"_\")\n        # print(file)\n        tree = ET.ElementTree(ET.fromstring(file))\n        root = tree.getroot()  # 获取根节点\n        # tree = ET.parse(xml_file)\n        # root = tree.getroot()\n        for member in root.findall(\"object\"):\n            classes_names.append(member[0].text)\n    classes_names = list(set(classes_names))\n    classes_names.sort()\n    return {name: i for i, name in enumerate(classes_names)}\n\n\ndef convert(xml_files, json_file):\n    json_dict = {\"images\": [], \"type\": \"instances\", \"annotations\": [], \"categories\": []}\n    if PRE_DEFINE_CATEGORIES is not None:\n        categories = PRE_DEFINE_CATEGORIES\n    else:\n        categories = get_categories(xml_files)\n    bnd_id = START_BOUNDING_BOX_ID\n    startIndex = 21800 # 修改这个很重要！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！\n    for xml_file in xml_files:\n        file = open(xml_file).read()\n        file = file.replace(\"&amp;\", \"_\")\n        file = file.replace(\"&\", \"_\")\n        # print(file)\n        tree = ET.ElementTree(ET.fromstring(file))\n        root = tree.getroot()  # 获取根节点\n        # tree = ET.parse(xml_file)\n        # root = tree.getroot()\n        path = get(root, \"path\")\n        if len(path) == 1:\n            filename = os.path.basename(path[0].text)\n        elif len(path) == 0:\n            filename = get_and_check(root, \"filename\", 1).text\n        else:\n            raise ValueError(\"%d paths found in %s\" % (len(path), xml_file))\n        ## The filename must be a number\n        image_id = startIndex\n        startIndex += 1\n        size = get_and_check(root, \"size\", 1)\n        width = int(get_and_check(size, \"width\", 1).text)\n        height = int(get_and_check(size, \"height\", 1).text)\n        image = {\n            \"file_name\": filename,\n            \"height\": height,\n            \"width\": width,\n            \"id\": image_id,\n        }\n        json_dict[\"images\"].append(image)\n        ## Currently we do not support segmentation.\n        #  segmented = get_and_check(root, 'segmented', 1).text\n        #  assert segmented == '0'\n        for obj in get(root, \"object\"):\n            category = get_and_check(obj, \"name\", 1).text\n            if category not in categories:\n                new_id = len(categories)\n                categories[category] = new_id\n            category_id = categories[category]\n            bndbox = get_and_check(obj, \"bndbox\", 1)\n            xmin = int(get_and_check(bndbox, \"xmin\", 1).text) - 1\n            ymin = int(get_and_check(bndbox, \"ymin\", 1).text) - 1\n            xmax = int(get_and_check(bndbox, \"xmax\", 1).text)\n            ymax = int(get_and_check(bndbox, \"ymax\", 1).text)\n            assert xmax > xmin\n            assert ymax > ymin\n            o_width = abs(xmax - xmin)\n            o_height = abs(ymax - ymin)\n            ann = {\n                \"area\": o_width * o_height,\n                \"iscrowd\": 0,\n                \"image_id\": image_id,\n                \"bbox\": [xmin, ymin, o_width, o_height],\n                \"category_id\": category_id,\n                \"id\": bnd_id,\n                \"ignore\": 0,\n                \"segmentation\": [],\n            }\n            json_dict[\"annotations\"].append(ann)\n            bnd_id = bnd_id + 1\n\n    for cate, cid in categories.items():\n        cat = {\"supercategory\": \"none\", \"id\": cid, \"name\": cate}\n        json_dict[\"categories\"].append(cat)\n\n    os.makedirs(os.path.dirname(json_file), exist_ok=True)\n    json_fp = open(json_file, \"w\")\n    json_str = json.dumps(json_dict)\n    json_fp.write(json_str)\n    json_fp.close()\n\n\nxml_val_files = glob.glob(os.path.join(xml_val, \"*.xml\"))\nxml_test_files = glob.glob(os.path.join(xml_test, \"*.xml\"))\nxml_train_files = glob.glob(os.path.join(xml_train, \"*.xml\"))\n\nconvert(xml_val_files, coco_json_annotations + 'val2017.json')\nconvert(xml_test_files, coco_json_annotations+'test2017.json')\nconvert(xml_train_files, coco_json_annotations + 'train2017.json')\n```\n\n","tags":["蝠鲼项目"]},{"title":"Hello World","url":"/2022/05/08/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n<!-- more -->\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]